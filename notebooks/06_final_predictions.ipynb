{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction - Final Predictions\n",
    "# ==================================================\n",
    "\n",
    "# ## üìã Objetivo\n",
    "# Generar predicciones finales usando nuestro modelo SVM entrenado:\n",
    "# - Cargar modelo final optimizado\n",
    "# - Aplicar pipeline completo de procesamiento\n",
    "# - Generar predicciones con an√°lisis de confianza\n",
    "# - Crear archivo final de predicciones\n",
    "# - Validar resultados y generar insights finales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5",
   "metadata": {},
   "source": [
    "## 1. Importaci√≥n de Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Funciones helper\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "from utils.helpers import save_current_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6g7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6g7h8",
   "metadata": {},
   "source": [
    "## 2. Carga de Modelo Final y M√©tricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6g7h8i9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ü§ñ CARGANDO MODELO FINAL\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Cargar modelo entrenado\n",
    "model_path = \"../models/best_model_svm.pkl\"\n",
    "try:\n",
    "    best_model = joblib.load(model_path)\n",
    "    print(f\"‚úÖ Modelo cargado exitosamente: {model_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: No se encuentra {model_path}\")\n",
    "    print(\"üí° Ejecuta primero el notebook 04_modeling.ipynb\")\n",
    "\n",
    "# Cargar m√©tricas del modelo\n",
    "with open(\"../models/model_metrics.json\", \"r\") as f:\n",
    "    model_metrics = json.load(f)\n",
    "\n",
    "print(f\"\\nüìä INFORMACI√ìN DEL MODELO:\")\n",
    "print(f\"  Algoritmo: {model_metrics['best_model']}\")\n",
    "print(f\"  Par√°metros: {model_metrics['best_params']}\")\n",
    "print(f\"  Accuracy final: {model_metrics['final_test_metrics']['accuracy']:.4f}\")\n",
    "print(f\"  F1-Score: {model_metrics['final_test_metrics']['f1']:.4f}\")\n",
    "print(f\"  AUC-ROC: {model_metrics['final_test_metrics']['auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g7h8i9j0",
   "metadata": {},
   "source": [
    "## 3. Funci√≥n de Procesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "h8i9j0k1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_titanic_data(df_raw):\n",
    "    \"\"\"\n",
    "    Aplica exactamente el mismo pipeline de procesamiento usado en entrenamiento\n",
    "    \"\"\"\n",
    "    print(\"üîß Aplicando pipeline de procesamiento...\")\n",
    "\n",
    "    # Copia para no modificar original\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    # === PASO 1: DATA CLEANING ===\n",
    "    print(\"  üìã Paso 1: Data Cleaning\")\n",
    "\n",
    "    # Eliminar variables irrelevantes (si existen)\n",
    "    cols_to_drop = [\"PassengerId\", \"Name\", \"Ticket\"]\n",
    "    cols_to_drop = [col for col in cols_to_drop if col in df.columns]\n",
    "    if cols_to_drop:\n",
    "        df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    # Manejar Cabin -> Cabin_Known\n",
    "    if \"Cabin\" in df.columns:\n",
    "        df[\"Cabin_Known\"] = df[\"Cabin\"].notna().astype(int)\n",
    "        df = df.drop(\"Cabin\", axis=1)\n",
    "\n",
    "    # Imputar Embarked con moda\n",
    "    if df[\"Embarked\"].isnull().any():\n",
    "        df[\"Embarked\"].fillna(\"S\", inplace=True)\n",
    "\n",
    "    # Imputar Age por grupo (Sex + Pclass)\n",
    "    if df[\"Age\"].isnull().any():\n",
    "        age_medians = df.groupby([\"Sex\", \"Pclass\"])[\"Age\"].median()\n",
    "\n",
    "        def impute_age(row):\n",
    "            if pd.isnull(row[\"Age\"]):\n",
    "                return age_medians[row[\"Sex\"], row[\"Pclass\"]]\n",
    "            return row[\"Age\"]\n",
    "\n",
    "        df[\"Age\"] = df.apply(impute_age, axis=1)\n",
    "\n",
    "    # === PASO 2: FEATURE ENGINEERING ===\n",
    "    print(\"  üîß Paso 2: Feature Engineering\")\n",
    "\n",
    "    # Variables derivadas\n",
    "    df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n",
    "    df[\"IsAlone\"] = (df[\"FamilySize\"] == 1).astype(int)\n",
    "\n",
    "    # Age groups\n",
    "    def categorize_age(age):\n",
    "        if age < 12:\n",
    "            return \"Child\"\n",
    "        elif age < 18:\n",
    "            return \"Teen\"\n",
    "        elif age < 35:\n",
    "            return \"Young_Adult\"\n",
    "        elif age < 60:\n",
    "            return \"Middle_Age\"\n",
    "        else:\n",
    "            return \"Senior\"\n",
    "\n",
    "    df[\"AgeGroup\"] = df[\"Age\"].apply(categorize_age)\n",
    "\n",
    "    # Fare bins\n",
    "    df[\"FareBin\"] = pd.qcut(\n",
    "        df[\"Fare\"], q=4, labels=[\"Low\", \"Medium\", \"High\", \"Premium\"]\n",
    "    )\n",
    "\n",
    "    # T√≠tulos - funci√≥n mejorada para generar todos los t√≠tulos necesarios\n",
    "    def infer_title(row):\n",
    "        if row[\"Sex\"] == \"male\":\n",
    "            if row[\"Age\"] < 16:\n",
    "                return \"Master\"\n",
    "            elif row[\"Pclass\"] == 1 and row[\"Age\"] > 50:\n",
    "                # Aproximaci√≥n para t√≠tulos de alta clase\n",
    "                return \"Officer\" if row[\"Fare\"] > 50 else \"Mr\"\n",
    "            else:\n",
    "                return \"Mr\"\n",
    "        else:  # female\n",
    "            if row[\"Age\"] < 16:\n",
    "                return \"Miss\"\n",
    "            elif row[\"SibSp\"] > 0:  # Married indicator\n",
    "                if row[\"Pclass\"] == 1 and row[\"Fare\"] > 100:\n",
    "                    return \"Royalty\"  # Aproximaci√≥n para alta sociedad\n",
    "                else:\n",
    "                    return \"Mrs\"\n",
    "            else:\n",
    "                if row[\"Pclass\"] == 1 and row[\"Age\"] > 40:\n",
    "                    return \"Rare\"  # Aproximaci√≥n para t√≠tulos raros\n",
    "                else:\n",
    "                    return \"Miss\"\n",
    "\n",
    "    df[\"Title_Simplified\"] = df.apply(infer_title, axis=1)\n",
    "\n",
    "    # Variables de interacci√≥n\n",
    "    df[\"Sex_Pclass\"] = df[\"Sex\"] + \"_Class\" + df[\"Pclass\"].astype(str)\n",
    "\n",
    "    def age_sex_category(row):\n",
    "        if row[\"AgeGroup\"] in [\"Child\", \"Teen\"]:\n",
    "            return \"Young\"\n",
    "        elif row[\"Sex\"] == \"female\":\n",
    "            return \"Adult_Female\"\n",
    "        else:\n",
    "            return \"Adult_Male\"\n",
    "\n",
    "    df[\"Age_Sex\"] = df.apply(age_sex_category, axis=1)\n",
    "\n",
    "    # === PASO 3: ENCODING ===\n",
    "    print(\"  üî¢ Paso 3: Encoding\")\n",
    "\n",
    "    # Label encoding\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    le_sex = LabelEncoder()\n",
    "    le_embarked = LabelEncoder()\n",
    "\n",
    "    df[\"Sex_Encoded\"] = le_sex.fit_transform(df[\"Sex\"])\n",
    "    df[\"Embarked_Encoded\"] = le_embarked.fit_transform(df[\"Embarked\"])\n",
    "\n",
    "    # Ordinal encoding\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "    age_order = [\"Child\", \"Teen\", \"Young_Adult\", \"Middle_Age\", \"Senior\"]\n",
    "    oe_age = OrdinalEncoder(categories=[age_order])\n",
    "    df[\"AgeGroup_Encoded\"] = oe_age.fit_transform(df[[\"AgeGroup\"]]).astype(int)\n",
    "\n",
    "    fare_order = [\"Low\", \"Medium\", \"High\", \"Premium\"]\n",
    "    oe_fare = OrdinalEncoder(categories=[fare_order])\n",
    "    df[\"FareBin_Encoded\"] = oe_fare.fit_transform(df[[\"FareBin\"]]).astype(int)\n",
    "\n",
    "    # One-hot encoding\n",
    "    title_dummies = pd.get_dummies(df[\"Title_Simplified\"], prefix=\"Title\")\n",
    "    sex_pclass_dummies = pd.get_dummies(df[\"Sex_Pclass\"], prefix=\"SexPclass\")\n",
    "    age_sex_dummies = pd.get_dummies(df[\"Age_Sex\"], prefix=\"AgeSex\")\n",
    "\n",
    "    df = pd.concat([df, title_dummies, sex_pclass_dummies, age_sex_dummies], axis=1)\n",
    "\n",
    "    # === PASO 4: SELECCI√ìN DE FEATURES FINALES ===\n",
    "    print(\"  üéØ Paso 4: Selecci√≥n de Features\")\n",
    "\n",
    "    # Variables base\n",
    "    base_features = [\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Cabin_Known\"]\n",
    "\n",
    "    # Features engineeradas\n",
    "    eng_features = [\"FamilySize\", \"IsAlone\"]\n",
    "\n",
    "    # Features encoded\n",
    "    encoded_features = [\n",
    "        \"Sex_Encoded\",\n",
    "        \"Embarked_Encoded\",\n",
    "        \"AgeGroup_Encoded\",\n",
    "        \"FareBin_Encoded\",\n",
    "    ]\n",
    "\n",
    "    # TODAS las columnas de t√≠tulos que el modelo espera\n",
    "    expected_title_columns = [\n",
    "        \"Title_Master\",\n",
    "        \"Title_Miss\",\n",
    "        \"Title_Mr\",\n",
    "        \"Title_Mrs\",\n",
    "        \"Title_Officer\",\n",
    "        \"Title_Rare\",\n",
    "        \"Title_Royalty\",\n",
    "    ]\n",
    "\n",
    "    # One-hot features esperadas\n",
    "    expected_sex_pclass = [\n",
    "        \"SexPclass_female_Class1\",\n",
    "        \"SexPclass_female_Class2\",\n",
    "        \"SexPclass_female_Class3\",\n",
    "        \"SexPclass_male_Class1\",\n",
    "        \"SexPclass_male_Class2\",\n",
    "        \"SexPclass_male_Class3\",\n",
    "    ]\n",
    "\n",
    "    expected_age_sex = [\"AgeSex_Adult_Female\", \"AgeSex_Adult_Male\", \"AgeSex_Young\"]\n",
    "\n",
    "    # Lista completa de columnas esperadas\n",
    "    expected_columns = (\n",
    "        base_features\n",
    "        + eng_features\n",
    "        + encoded_features\n",
    "        + expected_title_columns\n",
    "        + expected_sex_pclass\n",
    "        + expected_age_sex\n",
    "    )\n",
    "\n",
    "    # Crear DataFrame final con todas las columnas esperadas\n",
    "    df_final = pd.DataFrame(index=df.index)\n",
    "\n",
    "    # A√±adir columnas existentes\n",
    "    for col in expected_columns:\n",
    "        if col in df.columns:\n",
    "            df_final[col] = df[col]\n",
    "        else:\n",
    "            # A√±adir columnas faltantes con 0\n",
    "            df_final[col] = 0\n",
    "            print(f\"    ‚ö†Ô∏è Columna faltante a√±adida con 0: {col}\")\n",
    "\n",
    "    # === PASO 5: SCALING ===\n",
    "    print(\"  üìè Paso 5: Scaling\")\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    numeric_features = [\n",
    "        \"Pclass\",\n",
    "        \"Age\",\n",
    "        \"SibSp\",\n",
    "        \"Parch\",\n",
    "        \"Fare\",\n",
    "        \"FamilySize\",\n",
    "        \"Sex_Encoded\",\n",
    "        \"Embarked_Encoded\",\n",
    "        \"AgeGroup_Encoded\",\n",
    "        \"FareBin_Encoded\",\n",
    "    ]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    df_final[numeric_features] = scaler.fit_transform(df_final[numeric_features])\n",
    "\n",
    "    print(f\"  ‚úÖ Procesamiento completado: {df_final.shape}\")\n",
    "    print(f\"  üìã Columnas finales: {len(df_final.columns)}\")\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i9j0k1l2",
   "metadata": {},
   "source": [
    "## 4. Carga de Datos para Predicci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j0k1l2m3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä CARGANDO DATOS PARA PREDICCI√ìN\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Opci√≥n 1: Si tuvieras un test.csv separado (como en Kaggle)\n",
    "# test_data = pd.read_csv(\"../data/raw/test.csv\")\n",
    "\n",
    "# Opci√≥n 2: Usar una muestra del dataset original para demostraci√≥n\n",
    "original_data = pd.read_csv(\"../data/raw/titanic.csv\")\n",
    "\n",
    "# Para demostraci√≥n, usaremos los √∫ltimos 100 registros como \"test set\"\n",
    "demo_test_data = original_data.tail(100).copy()\n",
    "demo_test_passenger_ids = demo_test_data['PassengerId'].copy()\n",
    "\n",
    "# Simular que no conocemos las respuestas (eliminar Survived)\n",
    "demo_test_features = demo_test_data.drop('Survived', axis=1)\n",
    "true_labels = demo_test_data['Survived']  # Para validaci√≥n\n",
    "\n",
    "print(f\"üìã Datos de prueba cargados:\")\n",
    "print(f\"  - Registros: {len(demo_test_features)}\")\n",
    "print(f\"  - Features: {len(demo_test_features.columns)}\")\n",
    "print(f\"  - PassengerIds: {demo_test_passenger_ids.min()} - {demo_test_passenger_ids.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k1l2m3n4",
   "metadata": {},
   "source": [
    "## 5. Procesamiento de Datos de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l2m3n4o5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîß PROCESANDO DATOS DE TEST\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Aplicar pipeline completo\n",
    "test_processed = process_titanic_data(demo_test_features)\n",
    "\n",
    "print(f\"\\n‚úÖ Datos procesados exitosamente:\")\n",
    "print(f\"  - Shape final: {test_processed.shape}\")\n",
    "print(f\"  - Features preparadas para el modelo\")\n",
    "\n",
    "# Verificar que no hay valores faltantes\n",
    "missing_values = test_processed.isnull().sum().sum()\n",
    "print(f\"  - Valores faltantes: {missing_values}\")\n",
    "\n",
    "if missing_values == 0:\n",
    "    print(\"  ‚úÖ Sin valores faltantes - Listo para predicci√≥n\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è Hay valores faltantes que deben manejarse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m3n4o5p6",
   "metadata": {},
   "source": [
    "## 6. Generaci√≥n de Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n4o5p6q7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüéØ GENERANDO PREDICCIONES\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Predicciones binarias\n",
    "predictions = best_model.predict(test_processed)\n",
    "print(f\"‚úÖ Predicciones binarias generadas: {len(predictions)}\")\n",
    "\n",
    "# Probabilidades\n",
    "probabilities = best_model.predict_proba(test_processed)[:, 1]\n",
    "print(f\"‚úÖ Probabilidades generadas: {len(probabilities)}\")\n",
    "\n",
    "# Resumen de predicciones\n",
    "n_survived = predictions.sum()\n",
    "n_died = len(predictions) - n_survived\n",
    "survival_rate = n_survived / len(predictions)\n",
    "\n",
    "print(f\"\\nüìä RESUMEN DE PREDICCIONES:\")\n",
    "print(f\"  - Total pasajeros: {len(predictions)}\")\n",
    "print(f\"  - Predichos como supervivientes: {n_survived} ({survival_rate:.1%})\")\n",
    "print(f\"  - Predichos como fallecidos: {n_died} ({1-survival_rate:.1%})\")\n",
    "print(f\"  - Probabilidad promedio: {probabilities.mean():.3f}\")\n",
    "print(\n",
    "    f\"  - Rango de probabilidades: [{probabilities.min():.3f}, {probabilities.max():.3f}]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o5p6q7r8",
   "metadata": {},
   "source": [
    "## 7. An√°lisis de Confianza de Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p6q7r8s9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîç AN√ÅLISIS DE CONFIANZA\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Categorizar por nivel de confianza\n",
    "def confidence_level(prob):\n",
    "    confidence = abs(prob - 0.5)  # Distancia del threshold\n",
    "    if confidence >= 0.4:\n",
    "        return 'Muy Alta'\n",
    "    elif confidence >= 0.3:\n",
    "        return 'Alta'\n",
    "    elif confidence >= 0.2:\n",
    "        return 'Media'\n",
    "    else:\n",
    "        return 'Baja'\n",
    "\n",
    "confidence_levels = [confidence_level(p) for p in probabilities]\n",
    "confidence_counts = pd.Series(confidence_levels).value_counts()\n",
    "\n",
    "print(\"Distribuci√≥n de confianza:\")\n",
    "for level, count in confidence_counts.items():\n",
    "    print(f\"  - {level}: {count} predicciones ({count/len(predictions):.1%})\")\n",
    "\n",
    "# Casos de alta confianza\n",
    "high_confidence_mask = [confidence_level(p) == 'Muy Alta' for p in probabilities]\n",
    "high_confidence_count = sum(high_confidence_mask)\n",
    "\n",
    "print(f\"\\nüéØ Predicciones de muy alta confianza: {high_confidence_count}\")\n",
    "\n",
    "# Casos de baja confianza (m√°s inciertos)\n",
    "low_confidence_mask = [confidence_level(p) == 'Baja' for p in probabilities]\n",
    "low_confidence_count = sum(low_confidence_mask)\n",
    "\n",
    "print(f\"‚ö†Ô∏è Predicciones de baja confianza: {low_confidence_count}\")\n",
    "\n",
    "# Visualizaci√≥n de distribuci√≥n de probabilidades\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(probabilities, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.axvline(x=0.5, color='red', linestyle='--', label='Threshold = 0.5')\n",
    "plt.xlabel('Probabilidad de Supervivencia')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Distribuci√≥n de Probabilidades')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "confidence_counts.plot(kind='bar', color='lightgreen')\n",
    "plt.title('Distribuci√≥n de Niveles de Confianza')\n",
    "plt.xlabel('Nivel de Confianza')\n",
    "plt.ylabel('N√∫mero de Predicciones')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "pd.Series(predictions).value_counts().plot(kind='bar', color=['crimson', 'forestgreen'])\n",
    "plt.title('Predicciones Finales')\n",
    "plt.xlabel('Predicci√≥n (0=Muerte, 1=Supervivencia)')\n",
    "plt.ylabel('N√∫mero de Pasajeros')\n",
    "plt.xticks([0, 1], ['Fallecidos', 'Supervivientes'], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_current_plot('final_predictions_analysis', '../results/figures/final_predictions/')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56abd244",
   "metadata": {},
   "source": [
    "## 8. Validaci√≥n con Etiquetas Verdaderas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabf04e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚úÖ VALIDACI√ìN DE PREDICCIONES\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Como tenemos las etiquetas verdaderas, podemos validar\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# M√©tricas de validaci√≥n\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"üìä PERFORMANCE EN DATOS DE DEMO:\")\n",
    "print(f\"  - Accuracy: {accuracy:.4f} ({accuracy*100:.1f}%)\")\n",
    "\n",
    "# Reporte detallado\n",
    "print(f\"\\nüìã Reporte de clasificaci√≥n:\")\n",
    "print(\n",
    "    classification_report(\n",
    "        true_labels, predictions, target_names=[\"Fallecidos\", \"Supervivientes\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "print(f\"\\nüîç Matriz de confusi√≥n:\")\n",
    "print(cm)\n",
    "\n",
    "# Visualizaci√≥n de matriz de confusi√≥n\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"Fallecidos\", \"Supervivientes\"],\n",
    "    yticklabels=[\"Fallecidos\", \"Supervivientes\"],\n",
    ")\n",
    "plt.title(\"Matriz de Confusi√≥n - Datos Demo\")\n",
    "plt.xlabel(\"Predicci√≥n\")\n",
    "plt.ylabel(\"Valor Real\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Comparaci√≥n de distribuciones\n",
    "comparison_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Real\": true_labels.value_counts().sort_index(),\n",
    "        \"Predicho\": pd.Series(predictions).value_counts().sort_index(),\n",
    "    }\n",
    ")\n",
    "comparison_df.plot(kind=\"bar\", ax=plt.gca())\n",
    "plt.title(\"Comparaci√≥n: Real vs Predicho\")\n",
    "plt.xlabel(\"Supervivencia (0=No, 1=S√≠)\")\n",
    "plt.ylabel(\"N√∫mero de Pasajeros\")\n",
    "plt.xticks([0, 1], [\"Fallecidos\", \"Supervivientes\"], rotation=0)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "save_current_plot(\"validation_results\", \"../results/figures/final_predictions/\")\n",
    "plt.show()\n",
    "\n",
    "# An√°lisis de casos bien/mal clasificados\n",
    "correct_predictions = (true_labels == predictions).sum()\n",
    "incorrect_predictions = len(predictions) - correct_predictions\n",
    "\n",
    "print(f\"\\nüéØ AN√ÅLISIS DE ACIERTOS:\")\n",
    "print(\n",
    "    f\"  - Predicciones correctas: {correct_predictions} ({correct_predictions/len(predictions):.1%})\"\n",
    ")\n",
    "print(\n",
    "    f\"  - Predicciones incorrectas: {incorrect_predictions} ({incorrect_predictions/len(predictions):.1%})\"\n",
    ")\n",
    "\n",
    "# Comparar con performance esperada del modelo\n",
    "expected_accuracy = model_metrics[\"final_test_metrics\"][\"accuracy\"]\n",
    "performance_diff = accuracy - expected_accuracy\n",
    "\n",
    "print(f\"\\nüìà COMPARACI√ìN CON PERFORMANCE ESPERADA:\")\n",
    "print(f\"  - Accuracy esperada: {expected_accuracy:.4f}\")\n",
    "print(f\"  - Accuracy obtenida: {accuracy:.4f}\")\n",
    "print(f\"  - Diferencia: {performance_diff:+.4f}\")\n",
    "\n",
    "if abs(performance_diff) < 0.05:\n",
    "    print(\"  ‚úÖ Performance consistente con el modelo entrenado\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è Variaci√≥n significativa - normal en muestras peque√±as\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9424ce",
   "metadata": {},
   "source": [
    "## 9. Casos Interesantes de An√°lisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce60efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîç AN√ÅLISIS DE CASOS INTERESANTES\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "results_df = pd.DataFrame(\n",
    "    {\n",
    "        \"PassengerId\": demo_test_passenger_ids,\n",
    "        \"Prediction\": predictions,\n",
    "        \"Probability\": probabilities,\n",
    "        \"Confidence\": confidence_levels,\n",
    "        \"True_Label\": true_labels,\n",
    "        \"Correct\": (true_labels == predictions),\n",
    "    }\n",
    ")\n",
    "\n",
    "# A√±adir informaci√≥n demogr√°fica original\n",
    "demo_info = demo_test_data[\n",
    "    [\"PassengerId\", \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "].copy()\n",
    "results_df = results_df.merge(demo_info, on=\"PassengerId\")\n",
    "\n",
    "print(\"üéØ TOP 5 PREDICCIONES M√ÅS CONFIADAS (SUPERVIVIENTES):\")\n",
    "top_survivors = results_df[results_df[\"Prediction\"] == 1].nlargest(5, \"Probability\")\n",
    "for idx, row in top_survivors.iterrows():\n",
    "    status = \"‚úÖ\" if row[\"Correct\"] else \"‚ùå\"\n",
    "    print(\n",
    "        f\"  {status} ID {row['PassengerId']}: {row['Sex']}, Clase {row['Pclass']}, Edad {row['Age']:.0f} - Prob: {row['Probability']:.3f}\"\n",
    "    )\n",
    "\n",
    "print(\"\\nüíÄ TOP 5 PREDICCIONES M√ÅS CONFIADAS (FALLECIDOS):\")\n",
    "top_deaths = results_df[results_df[\"Prediction\"] == 0].nsmallest(5, \"Probability\")\n",
    "for idx, row in top_deaths.iterrows():\n",
    "    status = \"‚úÖ\" if row[\"Correct\"] else \"‚ùå\"\n",
    "    print(\n",
    "        f\"  {status} ID {row['PassengerId']}: {row['Sex']}, Clase {row['Pclass']}, Edad {row['Age']:.0f} - Prob: {row['Probability']:.3f}\"\n",
    "    )\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è TOP 5 PREDICCIONES MENOS CONFIADAS (M√ÅS INCIERTAS):\")\n",
    "uncertain_cases = results_df.iloc[(results_df[\"Probability\"] - 0.5).abs().argsort()[:5]]\n",
    "for idx, row in uncertain_cases.iterrows():\n",
    "    status = \"‚úÖ\" if row[\"Correct\"] else \"‚ùå\"\n",
    "    pred_text = \"Supervive\" if row[\"Prediction\"] == 1 else \"Muere\"\n",
    "    print(\n",
    "        f\"  {status} ID {row['PassengerId']}: {row['Sex']}, Clase {row['Pclass']}, Edad {row['Age']:.0f} - Pred: {pred_text} (Prob: {row['Probability']:.3f})\"\n",
    "    )\n",
    "\n",
    "# An√°lisis por caracter√≠sticas demogr√°ficas\n",
    "print(f\"\\nüìä AN√ÅLISIS POR CARACTER√çSTICAS:\")\n",
    "\n",
    "# Por g√©nero\n",
    "gender_analysis = (\n",
    "    results_df.groupby(\"Sex\")\n",
    "    .agg({\"Prediction\": \"mean\", \"Probability\": \"mean\", \"Correct\": \"mean\"})\n",
    "    .round(3)\n",
    ")\n",
    "print(\"\\nPor g√©nero:\")\n",
    "print(gender_analysis)\n",
    "\n",
    "# Por clase\n",
    "class_analysis = (\n",
    "    results_df.groupby(\"Pclass\")\n",
    "    .agg({\"Prediction\": \"mean\", \"Probability\": \"mean\", \"Correct\": \"mean\"})\n",
    "    .round(3)\n",
    ")\n",
    "print(\"\\nPor clase:\")\n",
    "print(class_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e1e624",
   "metadata": {},
   "source": [
    "## 10. Creaci√≥n de Archivo de Predicciones Finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5709eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüíæ CREANDO ARCHIVO DE PREDICCIONES FINALES\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Crear directorio si no existe\n",
    "import os\n",
    "\n",
    "os.makedirs(\"../results/final_predictions\", exist_ok=True)\n",
    "\n",
    "# Archivo de submission estilo Kaggle\n",
    "submission = pd.DataFrame(\n",
    "    {\"PassengerId\": demo_test_passenger_ids, \"Survived\": predictions}\n",
    ")\n",
    "\n",
    "submission_path = \"../results/final_predictions/titanic_predictions.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"‚úÖ Archivo de predicciones guardado: {submission_path}\")\n",
    "\n",
    "# Archivo detallado con probabilidades y an√°lisis\n",
    "detailed_results = pd.DataFrame(\n",
    "    {\n",
    "        \"PassengerId\": demo_test_passenger_ids,\n",
    "        \"Predicted_Survival\": predictions,\n",
    "        \"Survival_Probability\": probabilities.round(4),\n",
    "        \"Confidence_Level\": confidence_levels,\n",
    "        \"Passenger_Class\": demo_test_data[\"Pclass\"].values,\n",
    "        \"Sex\": demo_test_data[\"Sex\"].values,\n",
    "        \"Age\": demo_test_data[\"Age\"].values,\n",
    "        \"Fare\": demo_test_data[\"Fare\"].values,\n",
    "        \"Family_Size\": demo_test_data[\"SibSp\"].values\n",
    "        + demo_test_data[\"Parch\"].values\n",
    "        + 1,\n",
    "        \"Embarked\": demo_test_data[\"Embarked\"].values,\n",
    "    }\n",
    ")\n",
    "\n",
    "detailed_path = \"../results/final_predictions/detailed_predictions.csv\"\n",
    "detailed_results.to_csv(detailed_path, index=False)\n",
    "print(f\"‚úÖ Archivo detallado guardado: {detailed_path}\")\n",
    "\n",
    "# Archivo de m√©tricas y resumen\n",
    "summary_stats = {\n",
    "    \"model_used\": model_metrics[\"best_model\"],\n",
    "    \"model_params\": model_metrics[\"best_params\"],\n",
    "    \"model_training_accuracy\": model_metrics[\"final_test_metrics\"][\"accuracy\"],\n",
    "    \"predictions_generated\": len(predictions),\n",
    "    \"predicted_survivors\": int(predictions.sum()),\n",
    "    \"predicted_deaths\": int(len(predictions) - predictions.sum()),\n",
    "    \"survival_rate_predicted\": float(predictions.mean()),\n",
    "    \"average_probability\": float(probabilities.mean()),\n",
    "    \"high_confidence_predictions\": int(\n",
    "        sum([c == \"Muy Alta\" for c in confidence_levels])\n",
    "    ),\n",
    "    \"low_confidence_predictions\": int(sum([c == \"Baja\" for c in confidence_levels])),\n",
    "    \"validation_accuracy\": float(accuracy),\n",
    "    \"generation_timestamp\": datetime.now().isoformat(),\n",
    "}\n",
    "\n",
    "summary_path = \"../results/final_predictions/prediction_summary.json\"\n",
    "with open(summary_path, \"w\") as f:\n",
    "    json.dump(summary_stats, f, indent=2)\n",
    "print(f\"‚úÖ Resumen guardado: {summary_path}\")\n",
    "\n",
    "print(f\"\\nüìã ARCHIVOS GENERADOS:\")\n",
    "print(f\"  1. {submission_path} - Formato Kaggle submission\")\n",
    "print(f\"  2. {detailed_path} - An√°lisis detallado con probabilidades\")\n",
    "print(f\"  3. {summary_path} - Resumen y m√©tricas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025bf5ec",
   "metadata": {},
   "source": [
    "## 11. Insights Finales y Storytelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f37831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüé≠ INSIGHTS FINALES Y STORYTELLING\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "print(\"üö¢ HISTORIA DEL MODELO TITANIC:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "model_story = f\"\"\"\n",
    "Nuestro modelo SVM, entrenado con {model_metrics['best_model']} y optimizado con los par√°metros\n",
    "{model_metrics['best_params']}, ha demostrado una capacidad excepcional para predecir \n",
    "la supervivencia en el Titanic con un {model_metrics['final_test_metrics']['accuracy']*100:.1f}% de precisi√≥n.\n",
    "\n",
    "En esta demostraci√≥n con {len(predictions)} pasajeros:\n",
    "‚Ä¢ Predijimos que {predictions.sum()} sobrevivir√≠an ({predictions.mean()*100:.1f}%)\n",
    "‚Ä¢ {sum([c == 'Muy Alta' for c in confidence_levels])} predicciones fueron de muy alta confianza\n",
    "‚Ä¢ El modelo mantuvo {accuracy*100:.1f}% de precisi√≥n en estos datos de prueba\n",
    "\n",
    "Los patrones hist√≥ricos capturados por nuestro modelo reflejan la realidad social de 1912:\n",
    "‚Ä¢ Las mujeres de primera clase tuvieron las mayores probabilidades de supervivencia\n",
    "‚Ä¢ Los hombres de tercera clase enfrentaron las menores probabilidades\n",
    "‚Ä¢ El protocolo \"mujeres y ni√±os primero\" se refleja claramente en las predicciones\n",
    "\"\"\"\n",
    "\n",
    "print(model_story)\n",
    "\n",
    "print(\"\\nüéØ CASOS DESTACADOS:\")\n",
    "\n",
    "# Caso m√°s confiado de supervivencia\n",
    "most_confident_survivor = results_df[results_df[\"Prediction\"] == 1].loc[\n",
    "    results_df[\"Probability\"].idxmax()\n",
    "]\n",
    "print(f\"\\nüëë SUPERVIVIENTE M√ÅS PROBABLE:\")\n",
    "print(\n",
    "    f\"   Pasajero ID {most_confident_survivor['PassengerId']}: {most_confident_survivor['Sex']}, {most_confident_survivor['Age']:.0f} a√±os, Clase {most_confident_survivor['Pclass']}\"\n",
    ")\n",
    "print(f\"   Probabilidad: {most_confident_survivor['Probability']:.1%}\")\n",
    "print(f\"   Perfil: Representa el arquetipo de mayor supervivencia seg√∫n nuestro modelo\")\n",
    "\n",
    "# Caso m√°s confiado de muerte\n",
    "most_confident_death = results_df[results_df[\"Prediction\"] == 0].loc[\n",
    "    results_df[\"Probability\"].idxmin()\n",
    "]\n",
    "print(f\"\\nüíÄ FALLECIMIENTO M√ÅS PROBABLE:\")\n",
    "print(\n",
    "    f\"   Pasajero ID {most_confident_death['PassengerId']}: {most_confident_death['Sex']}, {most_confident_death['Age']:.0f} a√±os, Clase {most_confident_death['Pclass']}\"\n",
    ")\n",
    "print(f\"   Probabilidad de supervivencia: {most_confident_death['Probability']:.1%}\")\n",
    "print(f\"   Perfil: Representa las circunstancias m√°s desfavorables de la √©poca\")\n",
    "\n",
    "# Caso m√°s incierto\n",
    "most_uncertain = results_df.iloc[\n",
    "    (results_df[\"Probability\"] - 0.5).abs().argsort().iloc[0]\n",
    "]\n",
    "print(f\"\\n‚ùì CASO M√ÅS INCIERTO:\")\n",
    "print(\n",
    "    f\"   Pasajero ID {most_uncertain['PassengerId']}: {most_uncertain['Sex']}, {most_uncertain['Age']:.0f} a√±os, Clase {most_uncertain['Pclass']}\"\n",
    ")\n",
    "print(\n",
    "    f\"   Probabilidad: {most_uncertain['Probability']:.1%} (muy cerca del umbral 50%)\"\n",
    ")\n",
    "print(\n",
    "    f\"   Insight: Casos como este muestran la complejidad humana detr√°s de las estad√≠sticas\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüîÆ VALOR PREDICTIVO DEL MODELO:\")\n",
    "print(f\"Este modelo no solo predice supervivencia, sino que revela:\")\n",
    "print(f\"‚Ä¢ Patrones sociales de 1912 capturados cuantitativamente\")\n",
    "print(f\"‚Ä¢ La intersecci√≥n de g√©nero, clase social y edad como factores determinantes\")\n",
    "print(f\"‚Ä¢ Casos excepcionales que desaf√≠an las normas estad√≠sticas\")\n",
    "print(f\"‚Ä¢ Lecciones aplicables a protocolos de emergencia modernos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14c9465",
   "metadata": {},
   "source": [
    "## 12. Resumen y Pr√≥ximos Pasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e496b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüéØ RESUMEN DE PREDICCIONES FINALES\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "final_summary = f\"\"\"\n",
    "‚úÖ MISI√ìN CUMPLIDA - PREDICCIONES FINALES GENERADAS\n",
    "\n",
    "üìä ESTAD√çSTICAS FINALES:\n",
    "    ‚Ä¢ Modelo utilizado: {model_metrics['best_model']}\n",
    "    ‚Ä¢ Predicciones generadas: {len(predictions)}\n",
    "    ‚Ä¢ Accuracy de validaci√≥n: {accuracy:.1%}\n",
    "    ‚Ä¢ Predicciones de alta confianza: {sum([c == 'Muy Alta' for c in confidence_levels])}\n",
    "    ‚Ä¢ Archivos generados: 3 (submission, detallado, resumen)\n",
    "\n",
    "üéì VALOR ACAD√âMICO DEMOSTRADO:\n",
    "    ‚Ä¢ Pipeline completo de ML implementado exitosamente\n",
    "    ‚Ä¢ Modelo productivo capaz de generar predicciones nuevas\n",
    "    ‚Ä¢ An√°lisis de confianza y validaci√≥n incluidos\n",
    "    ‚Ä¢ Storytelling hist√≥rico conectado con resultados t√©cnicos\n",
    "\n",
    "üöÄ APLICABILIDAD PR√ÅCTICA:\n",
    "    ‚Ä¢ Modelo listo para ser utilizado en nuevos datos del Titanic\n",
    "    ‚Ä¢ Pipeline reproducible para otros datasets similares\n",
    "    ‚Ä¢ Metodolog√≠a aplicable a an√°lisis hist√≥ricos con ML\n",
    "    ‚Ä¢ Insights valiosos para dise√±o de protocolos de emergencia\n",
    "\"\"\"\n",
    "\n",
    "print(final_summary)\n",
    "\n",
    "print(\"\\nüîÑ POSIBLES EXTENSIONES:\")\n",
    "extensions = [\n",
    "    \"üåê Aplicar modelo a otros datasets hist√≥ricos de naufragios\",\n",
    "    \"üìä Crear dashboard interactivo con Streamlit/Dash\",\n",
    "    \"ü§ñ Implementar ensemble con m√∫ltiples modelos\",\n",
    "    \"üì± Desarrollar API REST para predicciones en tiempo real\",\n",
    "    \"üìö Ampliar an√°lisis con datos adicionales de Encyclopedia Titanica\",\n",
    "    \"üéØ Optimizar modelo para diferentes m√©tricas (recall, precision)\",\n",
    "]\n",
    "\n",
    "for ext in extensions:\n",
    "    print(f\"   {ext}\")\n",
    "\n",
    "print(f\"\\nüèÜ CONCLUSI√ìN:\")\n",
    "print(f\"El modelo Titanic ha demostrado no solo capacidad predictiva t√©cnica,\")\n",
    "print(f\"sino tambi√©n la habilidad de revelar patrones hist√≥ricos significativos.\")\n",
    "print(f\"Cada predicci√≥n cuenta una historia humana respaldada por datos.\")\n",
    "\n",
    "print(f\"\\n‚ú® ¬°Proyecto de Machine Learning completado exitosamente! ‚ú®\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
