{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4fe01ab",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction - Data Cleaning\n",
    "# ============================================\n",
    "\n",
    "# ## üìã Objetivo\n",
    "# Limpiar y preparar el dataset del Titanic para el modelado:\n",
    "# - Manejar valores faltantes (Age: 19.9%, Cabin: 77.1%, Embarked: 0.2%)\n",
    "# - Detectar y tratar outliers\n",
    "# - Eliminar variables irrelevantes\n",
    "# - Validar consistencia de datos\n",
    "# - Crear dataset limpio para feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80c964f",
   "metadata": {},
   "source": [
    "## 1. Importaci√≥n de Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d20f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "# Funciones helper\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "from utils.helpers import save_current_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b9449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eea4f76",
   "metadata": {},
   "source": [
    "## 2. Carga de Datos y Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b992d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset original\n",
    "df_original = pd.read_csv(\"../data/raw/titanic.csv\")\n",
    "df = df_original.copy()  # Copia de trabajo\n",
    "\n",
    "print(\"üö¢ INICIO DE LIMPIEZA DE DATOS\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"üìä Dataset original: {df.shape}\")\n",
    "print(f\"üë• Total de registros: {len(df)}\")\n",
    "\n",
    "# Backup de datos originales\n",
    "print(\"üíæ Creando backup de datos originales...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5059d57e",
   "metadata": {},
   "source": [
    "## 3. An√°lisis Inicial de Calidad de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8029d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîç AN√ÅLISIS DE CALIDAD DE DATOS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Informaci√≥n general\n",
    "print(\"Informaci√≥n del dataset:\")\n",
    "print(df.info())\n",
    "\n",
    "# Valores faltantes\n",
    "print(\"\\n‚ùå VALORES FALTANTES DETALLADOS:\")\n",
    "missing_analysis = pd.DataFrame(\n",
    "    {\n",
    "        \"Column\": df.columns,\n",
    "        \"Missing_Count\": df.isnull().sum(),\n",
    "        \"Missing_Percentage\": (df.isnull().sum() / len(df) * 100).round(2),\n",
    "        \"Data_Type\": df.dtypes,\n",
    "    }\n",
    ")\n",
    "missing_analysis = missing_analysis.sort_values(\"Missing_Count\", ascending=False)\n",
    "print(missing_analysis)\n",
    "\n",
    "# Visualizar valores faltantes\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "missing_data = df.isnull().sum()\n",
    "missing_data_filtered = missing_data[missing_data > 0]\n",
    "plt.bar(missing_data_filtered.index, missing_data_filtered.values, color=\"coral\")\n",
    "plt.title(\"Valores Faltantes por Columna\")\n",
    "plt.xlabel(\"Columnas\")\n",
    "plt.ylabel(\"Cantidad\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "missing_percentage = missing_data / len(df) * 100\n",
    "missing_percentage_filtered = missing_percentage[missing_percentage > 0]\n",
    "plt.bar(\n",
    "    missing_percentage_filtered.index,\n",
    "    missing_percentage_filtered.values,\n",
    "    color=\"lightblue\",\n",
    ")\n",
    "plt.title(\"Porcentaje de Valores Faltantes\")\n",
    "plt.xlabel(\"Columnas\")\n",
    "plt.ylabel(\"Porcentaje (%)\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdafb9ad",
   "metadata": {},
   "source": [
    "## 4. Estrategia de Limpieza por Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443e79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüéØ ESTRATEGIA DE LIMPIEZA\")\n",
    "print(\"=\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad61526",
   "metadata": {},
   "source": [
    "### 4.1 Variables a Eliminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd818ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üóëÔ∏è ELIMINACI√ìN DE VARIABLES IRRELEVANTES:\")\n",
    "\n",
    "# Variables identificadas como no predictivas en EDA\n",
    "columns_to_drop = [\"PassengerId\", \"Name\", \"Ticket\"]\n",
    "\n",
    "print(f\"Variables a eliminar: {columns_to_drop}\")\n",
    "print(\"Razones:\")\n",
    "print(\"- PassengerId: Identificador √∫nico, no tiene valor predictivo\")\n",
    "print(\"- Name: Informaci√≥n personal, extraeremos t√≠tulos por separado\")\n",
    "print(\"- Ticket: C√≥digo alfanum√©rico sin patr√≥n claro\")\n",
    "\n",
    "# Eliminar variables\n",
    "df_clean = df.drop(columns=columns_to_drop)\n",
    "print(f\"‚úÖ Variables eliminadas. Nueva dimensi√≥n: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4b2338",
   "metadata": {},
   "source": [
    "### 4.2 Manejo de Variable Cabin (77.1% faltantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf20f25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüè† MANEJO DE VARIABLE CABIN:\")\n",
    "print(\n",
    "    f\"Valores faltantes: {df_clean['Cabin'].isnull().sum()} ({df_clean['Cabin'].isnull().mean()*100:.1f}%)\"\n",
    ")\n",
    "\n",
    "# Analizar patrones en Cabin\n",
    "cabin_available = df_clean[\"Cabin\"].notna()\n",
    "print(f\"Registros con cabina: {cabin_available.sum()}\")\n",
    "print(f\"Registros sin cabina: {(~cabin_available).sum()}\")\n",
    "\n",
    "# Crear variable binaria: ten√≠a cabina asignada o no\n",
    "df_clean[\"Cabin_Known\"] = cabin_available.astype(int)\n",
    "\n",
    "# Analizar supervivencia por disponibilidad de cabina\n",
    "cabin_survival = pd.crosstab(\n",
    "    df_clean[\"Cabin_Known\"], df_clean[\"Survived\"], margins=True\n",
    ")\n",
    "print(\"\\nSupervivencia por disponibilidad de cabina:\")\n",
    "print(cabin_survival)\n",
    "\n",
    "cabin_survival_pct = (\n",
    "    pd.crosstab(df_clean[\"Cabin_Known\"], df_clean[\"Survived\"], normalize=\"index\") * 100\n",
    ")\n",
    "print(\"\\nPorcentajes:\")\n",
    "print(cabin_survival_pct.round(1))\n",
    "\n",
    "# Visualizaci√≥n\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(\n",
    "    data=df_clean, x=\"Cabin_Known\", y=\"Survived\", palette=[\"coral\", \"lightgreen\"]\n",
    ")\n",
    "plt.title(\"Supervivencia por Disponibilidad de Cabina\")\n",
    "plt.xlabel(\"Cabina Conocida (0=No, 1=S√≠)\")\n",
    "plt.ylabel(\"Tasa de Supervivencia\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(\n",
    "    data=df_clean, x=\"Cabin_Known\", hue=\"Survived\", palette=[\"crimson\", \"forestgreen\"]\n",
    ")\n",
    "plt.title(\"Conteo por Disponibilidad de Cabina\")\n",
    "plt.xlabel(\"Cabina Conocida (0=No, 1=S√≠)\")\n",
    "plt.ylabel(\"N√∫mero de Pasajeros\")\n",
    "\n",
    "plt.tight_layout()\n",
    "save_current_plot(\"cabin_analysis\", \"../results/figures/eda_plots\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Eliminar variable Cabin original\n",
    "df_clean = df_clean.drop(\"Cabin\", axis=1)\n",
    "print(\"‚úÖ Variable Cabin reemplazada por Cabin_Known (binaria)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f22307",
   "metadata": {},
   "source": [
    "### 4.3 Manejo de Variable Embarked (0.2% faltantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cfb08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚öì MANEJO DE VARIABLE EMBARKED:\")\n",
    "print(\n",
    "    f\"Valores faltantes: {df_clean['Embarked'].isnull().sum()} ({df_clean['Embarked'].isnull().mean()*100:.1f}%)\"\n",
    ")\n",
    "\n",
    "# Analizar los registros con Embarked faltante\n",
    "missing_embarked = df_clean[df_clean[\"Embarked\"].isnull()]\n",
    "print(\"\\nRegistros con Embarked faltante:\")\n",
    "print(missing_embarked[[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Survived\"]])\n",
    "\n",
    "# Distribuci√≥n de puertos\n",
    "embarked_counts = df_clean[\"Embarked\"].value_counts()\n",
    "print(f\"\\nDistribuci√≥n de puertos:\")\n",
    "print(embarked_counts)\n",
    "print(\n",
    "    f\"Puerto m√°s frecuente: {embarked_counts.index[0]} ({embarked_counts.iloc[0]} pasajeros)\"\n",
    ")\n",
    "\n",
    "# Imputar con la moda (Southampton - S)\n",
    "mode_embarked = df_clean[\"Embarked\"].mode()[0]\n",
    "df_clean[\"Embarked\"].fillna(mode_embarked, inplace=True)\n",
    "\n",
    "print(f\"‚úÖ Valores faltantes imputados con moda: '{mode_embarked}'\")\n",
    "print(\n",
    "    f\"Verificaci√≥n - Embarked faltantes despu√©s: {df_clean['Embarked'].isnull().sum()}\"\n",
    ")\n",
    "\n",
    "# ### 4.4 Manejo de Variable Age (19.9% faltantes)\n",
    "\n",
    "print(\"\\nüë∂üë¥ MANEJO DE VARIABLE AGE:\")\n",
    "print(\n",
    "    f\"Valores faltantes: {df_clean['Age'].isnull().sum()} ({df_clean['Age'].isnull().mean()*100:.1f}%)\"\n",
    ")\n",
    "\n",
    "# Estad√≠sticas b√°sicas de Age\n",
    "print(\"\\nEstad√≠sticas de Age (valores no nulos):\")\n",
    "print(df_clean[\"Age\"].describe())\n",
    "\n",
    "# Analizar patrones de Age faltantes\n",
    "age_missing = df_clean[\"Age\"].isnull()\n",
    "print(f\"\\nPatrones de Age faltante por otras variables:\")\n",
    "\n",
    "# Por g√©nero\n",
    "age_missing_by_sex = pd.crosstab(df_clean[\"Sex\"], age_missing, margins=True)\n",
    "print(\"\\nPor g√©nero:\")\n",
    "print(age_missing_by_sex)\n",
    "\n",
    "# Por clase\n",
    "age_missing_by_class = pd.crosstab(df_clean[\"Pclass\"], age_missing, margins=True)\n",
    "print(\"\\nPor clase:\")\n",
    "print(age_missing_by_class)\n",
    "\n",
    "# Estrategia de imputaci√≥n: mediana por grupo (Sex + Pclass)\n",
    "print(\"\\nüîß ESTRATEGIA DE IMPUTACI√ìN:\")\n",
    "print(\"Usando mediana por grupo (Sex + Pclass)\")\n",
    "\n",
    "# Calcular medianas por grupo\n",
    "age_medians = df_clean.groupby([\"Sex\", \"Pclass\"])[\"Age\"].median()\n",
    "print(\"\\nMedianas por grupo:\")\n",
    "print(age_medians)\n",
    "\n",
    "\n",
    "# Funci√≥n de imputaci√≥n\n",
    "def impute_age(row):\n",
    "    if pd.isnull(row[\"Age\"]):\n",
    "        return age_medians[row[\"Sex\"], row[\"Pclass\"]]\n",
    "    return row[\"Age\"]\n",
    "\n",
    "\n",
    "# Aplicar imputaci√≥n\n",
    "df_clean[\"Age\"] = df_clean.apply(impute_age, axis=1)\n",
    "\n",
    "print(f\"‚úÖ Age imputada. Valores faltantes despu√©s: {df_clean['Age'].isnull().sum()}\")\n",
    "\n",
    "# Visualizar distribuci√≥n antes y despu√©s\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "df_original[\"Age\"].hist(bins=30, alpha=0.7, color=\"coral\", label=\"Original\")\n",
    "plt.title(\"Distribuci√≥n Original de Age\")\n",
    "plt.xlabel(\"Edad\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "df_clean[\"Age\"].hist(\n",
    "    bins=30, alpha=0.7, color=\"lightgreen\", label=\"Despu√©s de Imputaci√≥n\"\n",
    ")\n",
    "plt.title(\"Distribuci√≥n Despu√©s de Imputaci√≥n\")\n",
    "plt.xlabel(\"Edad\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "df_original[\"Age\"].hist(bins=30, alpha=0.5, color=\"coral\", label=\"Original\")\n",
    "df_clean[\"Age\"].hist(bins=30, alpha=0.5, color=\"lightgreen\", label=\"Imputada\")\n",
    "plt.title(\"Comparaci√≥n de Distribuciones\")\n",
    "plt.xlabel(\"Edad\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "save_current_plot(\"age_imputation_comparison\", \"../results/figures/eda_plots\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087ca732",
   "metadata": {},
   "source": [
    "## 5. Detecci√≥n y Tratamiento de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34797c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüéØ DETECCI√ìN DE OUTLIERS\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Variables num√©ricas para an√°lisis de outliers\n",
    "numeric_vars = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "\n",
    "\n",
    "def detect_outliers_iqr(data, column):\n",
    "    \"\"\"Detecta outliers usando m√©todo IQR\"\"\"\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "\n",
    "# An√°lisis de outliers por variable\n",
    "outliers_summary = {}\n",
    "\n",
    "for var in numeric_vars:\n",
    "    outliers, lower, upper = detect_outliers_iqr(df_clean, var)\n",
    "    outliers_summary[var] = {\n",
    "        \"count\": len(outliers),\n",
    "        \"percentage\": len(outliers) / len(df_clean) * 100,\n",
    "        \"lower_bound\": lower,\n",
    "        \"upper_bound\": upper,\n",
    "    }\n",
    "\n",
    "    print(f\"\\n{var}:\")\n",
    "    print(\n",
    "        f\"  Outliers detectados: {len(outliers)} ({len(outliers)/len(df_clean)*100:.1f}%)\"\n",
    "    )\n",
    "    print(f\"  Rango normal: [{lower:.2f}, {upper:.2f}]\")\n",
    "    if len(outliers) > 0:\n",
    "        print(f\"  Valores outliers: {sorted(outliers[var].unique())}\")\n",
    "\n",
    "# Visualizaci√≥n de outliers\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "for i, var in enumerate(numeric_vars, 1):\n",
    "    plt.subplot(1, 4, i)\n",
    "    sns.boxplot(data=df_clean, y=var, color=\"lightblue\")\n",
    "    plt.title(f\"Boxplot de {var}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "save_current_plot(\"outliers_detection\", \"../results/figures/eda_plots\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d107b68a",
   "metadata": {},
   "source": [
    "5.1 Tratamiento Espec√≠fico de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aed345",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîß TRATAMIENTO DE OUTLIERS:\")\n",
    "\n",
    "# Fare: Analizar outliers extremos\n",
    "fare_outliers, _, fare_upper = detect_outliers_iqr(df_clean, \"Fare\")\n",
    "print(f\"\\nFare - Outliers superiores a ${fare_upper:.2f}:\")\n",
    "extreme_fare = df_clean[df_clean[\"Fare\"] > fare_upper].sort_values(\n",
    "    \"Fare\", ascending=False\n",
    ")\n",
    "print(extreme_fare[[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Survived\"]].head())\n",
    "\n",
    "# Decisi√≥n: Mantener outliers de Fare (pueden ser leg√≠timos - suite de lujo)\n",
    "print(\"‚úÖ Decisi√≥n: Mantener outliers de Fare (posibles suites de lujo)\")\n",
    "\n",
    "# Age: Verificar edades extremas\n",
    "age_outliers, age_lower, age_upper = detect_outliers_iqr(df_clean, \"Age\")\n",
    "print(f\"\\nAge - Outliers:\")\n",
    "print(f\"Menores a {age_lower:.1f} a√±os: {len(df_clean[df_clean['Age'] < age_lower])}\")\n",
    "print(f\"Mayores a {age_upper:.1f} a√±os: {len(df_clean[df_clean['Age'] > age_upper])}\")\n",
    "\n",
    "extreme_ages = df_clean[(df_clean[\"Age\"] < age_lower) | (df_clean[\"Age\"] > age_upper)]\n",
    "print(\"\\nEdades extremas:\")\n",
    "print(extreme_ages[[\"Sex\", \"Age\", \"Pclass\", \"Survived\"]].sort_values(\"Age\"))\n",
    "\n",
    "# Decisi√≥n: Mantener outliers de Age (beb√©s y ancianos son realistas en 1912)\n",
    "print(\"‚úÖ Decisi√≥n: Mantener outliers de Age (demogr√°ficamente realistas)\")\n",
    "\n",
    "# SibSp y Parch: Familias grandes\n",
    "sibsp_outliers = df_clean[df_clean[\"SibSp\"] > 3]\n",
    "parch_outliers = df_clean[df_clean[\"Parch\"] > 3]\n",
    "\n",
    "print(f\"\\nFamilias grandes:\")\n",
    "print(f\"SibSp > 3: {len(sibsp_outliers)} familias\")\n",
    "print(f\"Parch > 3: {len(parch_outliers)} familias\")\n",
    "\n",
    "# Decisi√≥n: Mantener (familias grandes eran comunes en 1912)\n",
    "print(\"‚úÖ Decisi√≥n: Mantener familias grandes (hist√≥ricamente v√°lidas)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84406c8c",
   "metadata": {},
   "source": [
    "## 6. Validaci√≥n de Consistencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f47d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚úÖ VALIDACI√ìN DE CONSISTENCIA\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Verificar rangos de variables\n",
    "consistency_checks = {\n",
    "    \"Age\": (df_clean[\"Age\"] >= 0) & (df_clean[\"Age\"] <= 120),\n",
    "    \"Fare\": df_clean[\"Fare\"] >= 0,\n",
    "    \"SibSp\": df_clean[\"SibSp\"] >= 0,\n",
    "    \"Parch\": df_clean[\"Parch\"] >= 0,\n",
    "    \"Pclass\": df_clean[\"Pclass\"].isin([1, 2, 3]),\n",
    "    \"Sex\": df_clean[\"Sex\"].isin([\"male\", \"female\"]),\n",
    "    \"Embarked\": df_clean[\"Embarked\"].isin([\"C\", \"Q\", \"S\"]),\n",
    "    \"Survived\": df_clean[\"Survived\"].isin([0, 1]),\n",
    "}\n",
    "\n",
    "print(\"Verificaci√≥n de consistencia:\")\n",
    "for var, check in consistency_checks.items():\n",
    "    inconsistent = (~check).sum()\n",
    "    print(f\"  {var}: {inconsistent} valores inconsistentes\")\n",
    "    if inconsistent > 0:\n",
    "        print(f\"    Valores problem√°ticos: {df_clean[~check][var].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62613d55",
   "metadata": {},
   "source": [
    "## 7. Verificaci√≥n Final del Dataset Limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133734b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüèÅ DATASET LIMPIO - VERIFICACI√ìN FINAL\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(\"üìä Dimensiones finales:\")\n",
    "print(f\"  Original: {df_original.shape}\")\n",
    "print(f\"  Limpio: {df_clean.shape}\")\n",
    "print(f\"  Filas eliminadas: {len(df_original) - len(df_clean)}\")\n",
    "print(f\"  Columnas eliminadas: {len(df_original.columns) - len(df_clean.columns)}\")\n",
    "\n",
    "print(\"\\nüìã Informaci√≥n del dataset limpio:\")\n",
    "print(df_clean.info())\n",
    "\n",
    "print(\"\\n‚ùå Verificaci√≥n final de valores faltantes:\")\n",
    "final_missing = df_clean.isnull().sum()\n",
    "print(final_missing[final_missing > 0])\n",
    "\n",
    "if final_missing.sum() == 0:\n",
    "    print(\"‚úÖ ¬°Perfecto! No quedan valores faltantes\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è A√∫n hay valores faltantes por manejar\")\n",
    "\n",
    "print(\"\\nüìà Estad√≠sticas descriptivas finales:\")\n",
    "print(df_clean.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7aec21",
   "metadata": {},
   "source": [
    "## 8. Resumen de Cambios Realizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4c270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìù RESUMEN DE LIMPIEZA DE DATOS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "changes_summary = {\n",
    "    \"Variables eliminadas\": [\"PassengerId\", \"Name\", \"Ticket\"],\n",
    "    \"Cabin\": \"Convertida a variable binaria 'Cabin_Known'\",\n",
    "    \"Embarked\": \"2 valores faltantes imputados con moda ('S')\",\n",
    "    \"Age\": \"177 valores faltantes imputados con mediana por grupo (Sex + Pclass)\",\n",
    "    \"Outliers\": \"Detectados pero mantenidos (hist√≥ricamente v√°lidos)\",\n",
    "    \"Nuevas variables\": [\"Cabin_Known\"],\n",
    "    \"Variables finales\": len(df_clean.columns),\n",
    "    \"Registros finales\": len(df_clean),\n",
    "}\n",
    "\n",
    "for key, value in changes_summary.items():\n",
    "    print(f\"‚úÖ {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7ec231",
   "metadata": {},
   "source": [
    "## 9. Guardar Dataset Limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85713c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüíæ GUARDANDO DATASET LIMPIO\")\n",
    "print(\"=\" * 28)\n",
    "\n",
    "# Guardar en data/processed/\n",
    "output_path = \"../data/processed/train_processed.csv\"\n",
    "df_clean.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Dataset limpio guardado en: {output_path}\")\n",
    "print(f\"üìä Archivo guardado: {df_clean.shape[0]} filas √ó {df_clean.shape[1]} columnas\")\n",
    "\n",
    "# Verificar que se guard√≥ correctamente\n",
    "df_verify = pd.read_csv(output_path)\n",
    "print(f\"üîç Verificaci√≥n: archivo le√≠do correctamente ({df_verify.shape})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6184e249",
   "metadata": {},
   "source": [
    "## 10. Pr√≥ximos Pasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1f3249",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüöÄ PR√ìXIMOS PASOS\")\n",
    "print(\"=\" * 18)\n",
    "\n",
    "next_steps = [\n",
    "    \"Feature Engineering (03_feature_engineering.ipynb)\",\n",
    "    \"- Crear variable FamilySize (SibSp + Parch + 1)\",\n",
    "    \"- Extraer t√≠tulos de nombres (Mr, Mrs, Miss, Master, etc.)\",\n",
    "    \"- Crear categor√≠as de edad (Child, Adult, Senior)\",\n",
    "    \"- Crear bins de tarifa (Low, Medium, High, Premium)\",\n",
    "    \"- Encoding de variables categ√≥ricas\",\n",
    "    \"- Scaling de variables num√©ricas\",\n",
    "    \"Modelado (04_modeling.ipynb)\",\n",
    "    \"- Split train/validation/test\",\n",
    "    \"- Implementar algoritmos: Logistic Regression, Random Forest, SVM, Naive Bayes\",\n",
    "    \"- Cross-validation y hyperparameter tuning\",\n",
    "]\n",
    "\n",
    "for i, step in enumerate(next_steps, 1):\n",
    "    if step.startswith(\"-\"):\n",
    "        print(f\"  {step}\")\n",
    "    else:\n",
    "        print(f\"{i}. {step}\")\n",
    "\n",
    "print(\"\\n‚úÖ ¬°Limpieza de datos completada exitosamente!\")\n",
    "print(\"üìä Dataset listo para Feature Engineering\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
