{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "349d928a",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction - Machine Learning Modeling\n",
    "# =======================================================\n",
    "\n",
    "# ## üìã Objetivo\n",
    "# Implementar y comparar m√∫ltiples algoritmos de Machine Learning para predecir supervivencia:\n",
    "# - Logistic Regression (baseline interpretable)\n",
    "# - Random Forest (ensemble robusto)\n",
    "# - Support Vector Machine (boundaries complejas)\n",
    "# - Naive Bayes (baseline probabil√≠stico)\n",
    "# - Evaluar performance y seleccionar mejor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be79cc",
   "metadata": {},
   "source": [
    "## 1. Importaci√≥n de Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0708d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                            roc_auc_score, classification_report, confusion_matrix, roc_curve)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# Funciones helper\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "from utils.helpers import save_current_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011ac1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebdc719",
   "metadata": {},
   "source": [
    "## 2. Carga de Datos Procesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad0dff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset con features engineering\n",
    "df_features = pd.read_csv(\"../data/processed/features_engineered.csv\")\n",
    "df_scaled = pd.read_csv(\"../data/processed/features_scaled.csv\")\n",
    "\n",
    "print(\"üö¢ DATASETS CARGADOS\")\n",
    "print(\"=\" * 25)\n",
    "print(f\"üìä Features engineered: {df_features.shape}\")\n",
    "print(f\"üìä Features scaled: {df_scaled.shape}\")\n",
    "\n",
    "# Verificar consistencia\n",
    "print(f\"\\nüîç Verificaci√≥n:\")\n",
    "print(f\"  - Mismas dimensiones: {df_features.shape == df_scaled.shape}\")\n",
    "print(\n",
    "    f\"  - Variables objetivo iguales: {df_features['Survived'].equals(df_scaled['Survived'])}\"\n",
    ")\n",
    "\n",
    "print(\"\\nüìã Variables disponibles:\")\n",
    "print(f\"Total features: {len(df_features.columns)}\")\n",
    "print(\"\\nTipos de features:\")\n",
    "feature_types = {\n",
    "    \"Original\": [\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Cabin_Known\"],\n",
    "    \"Engineered\": [\"FamilySize\", \"IsAlone\"],\n",
    "    \"Encoded\": [\n",
    "        \"Sex_Encoded\",\n",
    "        \"Embarked_Encoded\",\n",
    "        \"AgeGroup_Encoded\",\n",
    "        \"FareBin_Encoded\",\n",
    "    ],\n",
    "    \"Interaction\": [\n",
    "        col\n",
    "        for col in df_features.columns\n",
    "        if any(x in col for x in [\"Title_\", \"SexPclass_\", \"AgeSex_\"])\n",
    "    ],\n",
    "}\n",
    "\n",
    "for ftype, features in feature_types.items():\n",
    "    available_features = [f for f in features if f in df_features.columns]\n",
    "    print(f\"  - {ftype}: {len(available_features)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee8b57f",
   "metadata": {},
   "source": [
    "## 3. Preparaci√≥n de Datos para Modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b92463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüéØ PREPARACI√ìN DE DATOS PARA MODELADO\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Separar features y target\n",
    "X = df_scaled.drop(\"Survived\", axis=1)\n",
    "y = df_scaled[\"Survived\"]\n",
    "\n",
    "print(f\"üìä Matriz de features (X): {X.shape}\")\n",
    "print(f\"üéØ Variable objetivo (y): {y.shape}\")\n",
    "print(f\"üìà Distribuci√≥n de clases: {y.value_counts().to_dict()}\")\n",
    "print(f\"‚öñÔ∏è Balance de clases: {y.mean():.3f} (38.4% supervivencia)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a9d7a7",
   "metadata": {},
   "source": [
    "### 3.1 Split Train/Validation/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114acda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîÑ DIVISI√ìN DE DATOS\")\n",
    "print(\"=\" * 20)\n",
    "\n",
    "# Split inicial: 80% train+val, 20% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Split train/validation: 70% train, 10% validation del total\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.125,\n",
    "    random_state=42,\n",
    "    stratify=y_temp,  # 0.125 de 0.8 = 0.1 del total\n",
    ")\n",
    "\n",
    "print(f\"üìä Dimensiones finales:\")\n",
    "print(f\"  - Train: {X_train.shape[0]} muestras ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"  - Validation: {X_val.shape[0]} muestras ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"  - Test: {X_test.shape[0]} muestras ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è Balance por conjunto:\")\n",
    "print(f\"  - Train: {y_train.mean():.3f}\")\n",
    "print(f\"  - Validation: {y_val.mean():.3f}\")\n",
    "print(f\"  - Test: {y_test.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b35b91",
   "metadata": {},
   "source": [
    "## 4. Implementaci√≥n de Modelos Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9a7501",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nü§ñ IMPLEMENTACI√ìN DE MODELOS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Diccionario para almacenar modelos\n",
    "models = {}\n",
    "model_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56dc829",
   "metadata": {},
   "source": [
    "### 4.1 Logistic Regression (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbc3b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä MODELO 1: LOGISTIC REGRESSION\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Modelo base\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_lr_train = lr_model.predict(X_train)\n",
    "y_pred_lr_val = lr_model.predict(X_val)\n",
    "y_proba_lr_val = lr_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# M√©tricas\n",
    "lr_metrics = {\n",
    "    \"train_accuracy\": accuracy_score(y_train, y_pred_lr_train),\n",
    "    \"val_accuracy\": accuracy_score(y_val, y_pred_lr_val),\n",
    "    \"val_precision\": precision_score(y_val, y_pred_lr_val),\n",
    "    \"val_recall\": recall_score(y_val, y_pred_lr_val),\n",
    "    \"val_f1\": f1_score(y_val, y_pred_lr_val),\n",
    "    \"val_auc\": roc_auc_score(y_val, y_proba_lr_val),\n",
    "}\n",
    "\n",
    "print(\"M√©tricas Logistic Regression:\")\n",
    "for metric, value in lr_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "models[\"Logistic Regression\"] = lr_model\n",
    "model_results[\"Logistic Regression\"] = lr_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01e53e1",
   "metadata": {},
   "source": [
    "### 4.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4148e0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüå≤ MODELO 2: RANDOM FOREST\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Modelo base\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_rf_train = rf_model.predict(X_train)\n",
    "y_pred_rf_val = rf_model.predict(X_val)\n",
    "y_proba_rf_val = rf_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# M√©tricas\n",
    "rf_metrics = {\n",
    "    \"train_accuracy\": accuracy_score(y_train, y_pred_rf_train),\n",
    "    \"val_accuracy\": accuracy_score(y_val, y_pred_rf_val),\n",
    "    \"val_precision\": precision_score(y_val, y_pred_rf_val),\n",
    "    \"val_recall\": recall_score(y_val, y_pred_rf_val),\n",
    "    \"val_f1\": f1_score(y_val, y_pred_rf_val),\n",
    "    \"val_auc\": roc_auc_score(y_val, y_proba_rf_val),\n",
    "}\n",
    "\n",
    "print(\"M√©tricas Random Forest:\")\n",
    "for metric, value in rf_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "models[\"Random Forest\"] = rf_model\n",
    "model_results[\"Random Forest\"] = rf_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcc6535",
   "metadata": {},
   "source": [
    "### 4.3 Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f4a059",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüéØ MODELO 3: SUPPORT VECTOR MACHINE\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Modelo base\n",
    "svm_model = SVC(kernel=\"rbf\", probability=True, random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_svm_train = svm_model.predict(X_train)\n",
    "y_pred_svm_val = svm_model.predict(X_val)\n",
    "y_proba_svm_val = svm_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# M√©tricas\n",
    "svm_metrics = {\n",
    "    \"train_accuracy\": accuracy_score(y_train, y_pred_svm_train),\n",
    "    \"val_accuracy\": accuracy_score(y_val, y_pred_svm_val),\n",
    "    \"val_precision\": precision_score(y_val, y_pred_svm_val),\n",
    "    \"val_recall\": recall_score(y_val, y_pred_svm_val),\n",
    "    \"val_f1\": f1_score(y_val, y_pred_svm_val),\n",
    "    \"val_auc\": roc_auc_score(y_val, y_proba_svm_val),\n",
    "}\n",
    "\n",
    "print(\"M√©tricas SVM:\")\n",
    "for metric, value in svm_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "models[\"SVM\"] = svm_model\n",
    "model_results[\"SVM\"] = svm_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feec0ec4",
   "metadata": {},
   "source": [
    "### 4.4 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîÆ MODELO 4: NAIVE BAYES\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Modelo base\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_nb_train = nb_model.predict(X_train)\n",
    "y_pred_nb_val = nb_model.predict(X_val)\n",
    "y_proba_nb_val = nb_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# M√©tricas\n",
    "nb_metrics = {\n",
    "    \"train_accuracy\": accuracy_score(y_train, y_pred_nb_train),\n",
    "    \"val_accuracy\": accuracy_score(y_val, y_pred_nb_val),\n",
    "    \"val_precision\": precision_score(y_val, y_pred_nb_val),\n",
    "    \"val_recall\": recall_score(y_val, y_pred_nb_val),\n",
    "    \"val_f1\": f1_score(y_val, y_pred_nb_val),\n",
    "    \"val_auc\": roc_auc_score(y_val, y_proba_nb_val),\n",
    "}\n",
    "\n",
    "print(\"M√©tricas Naive Bayes:\")\n",
    "for metric, value in nb_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "models[\"Naive Bayes\"] = nb_model\n",
    "model_results[\"Naive Bayes\"] = nb_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1581a47c",
   "metadata": {},
   "source": [
    "## 5. Comparaci√≥n de Modelos Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c7bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä COMPARACI√ìN DE MODELOS BASE\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Crear DataFrame de comparaci√≥n\n",
    "comparison_df = pd.DataFrame(model_results).T\n",
    "comparison_df = comparison_df.round(4)\n",
    "\n",
    "print(\"Tabla de comparaci√≥n:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Visualizaci√≥n de comparaci√≥n\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# M√©tricas de validaci√≥n\n",
    "val_metrics = [\"val_accuracy\", \"val_precision\", \"val_recall\", \"val_f1\", \"val_auc\"]\n",
    "metric_names = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"AUC-ROC\"]\n",
    "\n",
    "for i, (metric, name) in enumerate(zip(val_metrics, metric_names), 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    values = comparison_df[metric]\n",
    "    colors = [\"skyblue\", \"lightgreen\", \"coral\", \"gold\"]\n",
    "    bars = plt.bar(values.index, values.values, color=colors)\n",
    "    plt.title(f\"{name} en Validaci√≥n\")\n",
    "    plt.ylabel(name)\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # A√±adir valores en las barras\n",
    "    for bar, value in zip(bars, values.values):\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height() + 0.01,\n",
    "            f\"{value:.3f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "        )\n",
    "\n",
    "# Gr√°fico de overfitting (Train vs Val Accuracy)\n",
    "plt.subplot(2, 3, 6)\n",
    "train_acc = comparison_df[\"train_accuracy\"]\n",
    "val_acc = comparison_df[\"val_accuracy\"]\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width / 2, train_acc, width, label=\"Train\", alpha=0.7, color=\"lightblue\")\n",
    "plt.bar(\n",
    "    x + width / 2, val_acc, width, label=\"Validation\", alpha=0.7, color=\"lightcoral\"\n",
    ")\n",
    "plt.xlabel(\"Modelos\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Train vs Validation Accuracy\")\n",
    "plt.xticks(x, train_acc.index, rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "save_current_plot(\"models_comparison\", \"../results/figures/modeling\")\n",
    "plt.show()\n",
    "\n",
    "# Identificar mejor modelo base\n",
    "best_metric = \"val_f1\"  # M√©trica balanceada\n",
    "best_model_name = comparison_df[best_metric].idxmax()\n",
    "best_score = comparison_df.loc[best_model_name, best_metric]\n",
    "\n",
    "print(f\"\\nüèÜ Mejor modelo base: {best_model_name}\")\n",
    "print(f\"üìà {best_metric}: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5180920",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation para Robustez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41297166",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîÑ CROSS-VALIDATION PARA ROBUSTEZ\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Configurar CV estratificado\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEvaluando {name} con 5-Fold CV:\")\n",
    "\n",
    "    # M√∫ltiples m√©tricas\n",
    "    cv_accuracy = cross_val_score(\n",
    "        model, X_temp, y_temp, cv=cv_strategy, scoring=\"accuracy\"\n",
    "    )\n",
    "    cv_f1 = cross_val_score(model, X_temp, y_temp, cv=cv_strategy, scoring=\"f1\")\n",
    "    cv_auc = cross_val_score(model, X_temp, y_temp, cv=cv_strategy, scoring=\"roc_auc\")\n",
    "\n",
    "    cv_results[name] = {\n",
    "        \"accuracy_mean\": cv_accuracy.mean(),\n",
    "        \"accuracy_std\": cv_accuracy.std(),\n",
    "        \"f1_mean\": cv_f1.mean(),\n",
    "        \"f1_std\": cv_f1.std(),\n",
    "        \"auc_mean\": cv_auc.mean(),\n",
    "        \"auc_std\": cv_auc.std(),\n",
    "    }\n",
    "\n",
    "    print(f\"  Accuracy: {cv_accuracy.mean():.4f} ¬± {cv_accuracy.std():.4f}\")\n",
    "    print(f\"  F1-Score: {cv_f1.mean():.4f} ¬± {cv_f1.std():.4f}\")\n",
    "    print(f\"  AUC-ROC: {cv_auc.mean():.4f} ¬± {cv_auc.std():.4f}\")\n",
    "\n",
    "# Visualizaci√≥n CV\n",
    "cv_df = pd.DataFrame(cv_results).T\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "metrics = [\"accuracy\", \"f1\", \"auc\"]\n",
    "titles = [\"Accuracy\", \"F1-Score\", \"AUC-ROC\"]\n",
    "\n",
    "for i, (metric, title) in enumerate(zip(metrics, titles), 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    means = cv_df[f\"{metric}_mean\"]\n",
    "    stds = cv_df[f\"{metric}_std\"]\n",
    "\n",
    "    plt.errorbar(range(len(means)), means, yerr=stds, fmt=\"o\", capsize=5, capthick=2)\n",
    "    plt.xticks(range(len(means)), means.index, rotation=45)\n",
    "    plt.ylabel(title)\n",
    "    plt.title(f\"{title} - Cross Validation\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_current_plot(\"cross_validation_results\", \"../results/figures/modeling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6970cfcd",
   "metadata": {},
   "source": [
    "## 7. Hyperparameter Tuning del Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6afd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüîß HYPERPARAMETER TUNING: {best_model_name.upper()}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Definir grids de par√°metros\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "        \"penalty\": [\"l1\", \"l2\"],\n",
    "        \"solver\": [\"liblinear\", \"saga\"],\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [3, 5, 10, None],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"C\": [0.1, 1, 10, 100],\n",
    "        \"kernel\": [\"linear\", \"rbf\"],\n",
    "        \"gamma\": [\"scale\", \"auto\"],\n",
    "    },\n",
    "    \"Naive Bayes\": {\"var_smoothing\": [1e-9, 1e-8, 1e-7, 1e-6]},\n",
    "}\n",
    "\n",
    "# Grid Search del mejor modelo\n",
    "best_base_model = models[best_model_name]\n",
    "param_grid = param_grids[best_model_name]\n",
    "\n",
    "print(f\"Optimizando par√°metros de {best_model_name}...\")\n",
    "print(f\"Grid de b√∫squeda: {param_grid}\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=best_base_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv_strategy,\n",
    "    scoring=\"f1\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_temp, y_temp)\n",
    "\n",
    "print(f\"\\nüéØ Mejores par√°metros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"\\nüìà Mejor score (F1): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Modelo optimizado\n",
    "best_model_tuned = grid_search.best_estimator_\n",
    "\n",
    "# Evaluar modelo optimizado\n",
    "y_pred_tuned_train = best_model_tuned.predict(X_train)\n",
    "y_pred_tuned_val = best_model_tuned.predict(X_val)\n",
    "y_proba_tuned_val = best_model_tuned.predict_proba(X_val)[:, 1]\n",
    "\n",
    "tuned_metrics = {\n",
    "    \"train_accuracy\": accuracy_score(y_train, y_pred_tuned_train),\n",
    "    \"val_accuracy\": accuracy_score(y_val, y_pred_tuned_val),\n",
    "    \"val_precision\": precision_score(y_val, y_pred_tuned_val),\n",
    "    \"val_recall\": recall_score(y_val, y_pred_tuned_val),\n",
    "    \"val_f1\": f1_score(y_val, y_pred_tuned_val),\n",
    "    \"val_auc\": roc_auc_score(y_val, y_proba_tuned_val),\n",
    "}\n",
    "\n",
    "print(f\"\\nüìä M√©tricas del modelo optimizado:\")\n",
    "for metric, value in tuned_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8644e3",
   "metadata": {},
   "source": [
    "## 8. Evaluaci√≥n Final en Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9553f55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüèÅ EVALUACI√ìN FINAL EN TEST SET\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Evaluar modelo optimizado en test\n",
    "y_pred_test = best_model_tuned.predict(X_test)\n",
    "y_proba_test = best_model_tuned.predict_proba(X_test)[:, 1]\n",
    "\n",
    "test_metrics = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred_test),\n",
    "    \"precision\": precision_score(y_test, y_pred_test),\n",
    "    \"recall\": recall_score(y_test, y_pred_test),\n",
    "    \"f1\": f1_score(y_test, y_pred_test),\n",
    "    \"auc\": roc_auc_score(y_test, y_proba_test),\n",
    "}\n",
    "\n",
    "print(f\"üìä M√âTRICAS FINALES DEL MODELO OPTIMIZADO:\")\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "print(f\"\\nüìã Matriz de Confusi√≥n:\")\n",
    "print(cm)\n",
    "\n",
    "# Reporte de clasificaci√≥n\n",
    "print(f\"\\nüìù Reporte de Clasificaci√≥n:\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test, y_pred_test, target_names=[\"No Sobrevivi√≥\", \"Sobrevivi√≥\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Visualizaci√≥n de resultados finales\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"No Sobrevivi√≥\", \"Sobrevivi√≥\"],\n",
    "    yticklabels=[\"No Sobrevivi√≥\", \"Sobrevivi√≥\"],\n",
    ")\n",
    "plt.title(\"Matriz de Confusi√≥n - Test Set\")\n",
    "plt.xlabel(\"Predicci√≥n\")\n",
    "plt.ylabel(\"Valor Real\")\n",
    "\n",
    "# Curva ROC\n",
    "plt.subplot(1, 3, 2)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba_test)\n",
    "plt.plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {test_metrics[\"auc\"]:.3f})')\n",
    "plt.plot([0, 1], [0, 1], \"k--\", linewidth=1, label=\"Random Classifier\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Curva ROC - Test Set\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Distribuci√≥n de probabilidades\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(\n",
    "    y_proba_test[y_test == 0], bins=20, alpha=0.7, label=\"No Sobrevivi√≥\", color=\"red\"\n",
    ")\n",
    "plt.hist(\n",
    "    y_proba_test[y_test == 1], bins=20, alpha=0.7, label=\"Sobrevivi√≥\", color=\"green\"\n",
    ")\n",
    "plt.xlabel(\"Probabilidad Predicha\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.title(\"Distribuci√≥n de Probabilidades\")\n",
    "plt.legend()\n",
    "plt.axvline(x=0.5, color=\"black\", linestyle=\"--\", alpha=0.7, label=\"Threshold=0.5\")\n",
    "\n",
    "plt.tight_layout()\n",
    "save_current_plot(\"final_evaluation\", \"../results/figures/modeling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b5eade",
   "metadata": {},
   "source": [
    "## 9. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ef22fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîç AN√ÅLISIS DE FEATURE IMPORTANCE\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Feature importance (si el modelo lo soporta)\n",
    "if hasattr(best_model_tuned, \"feature_importances_\"):\n",
    "    feature_importance = pd.DataFrame(\n",
    "        {\"feature\": X.columns, \"importance\": best_model_tuned.feature_importances_}\n",
    "    ).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    print(\"Top 15 features m√°s importantes:\")\n",
    "    print(feature_importance.head(15))\n",
    "\n",
    "    # Visualizaci√≥n\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = feature_importance.head(15)\n",
    "    sns.barplot(data=top_features, y=\"feature\", x=\"importance\", palette=\"viridis\")\n",
    "    plt.title(\"Top 15 Features M√°s Importantes\")\n",
    "    plt.xlabel(\"Importancia\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.tight_layout()\n",
    "    save_current_plot(\"feature_importance\", \"../results/figures/modeling\")\n",
    "    plt.show()\n",
    "\n",
    "elif hasattr(best_model_tuned, \"coef_\"):\n",
    "    # Para modelos lineales (Logistic Regression)\n",
    "    feature_coef = pd.DataFrame(\n",
    "        {\n",
    "            \"feature\": X.columns,\n",
    "            \"coefficient\": best_model_tuned.coef_[0],\n",
    "            \"abs_coefficient\": np.abs(best_model_tuned.coef_[0]),\n",
    "        }\n",
    "    ).sort_values(\"abs_coefficient\", ascending=False)\n",
    "\n",
    "    print(\"Top 15 coeficientes m√°s importantes:\")\n",
    "    print(feature_coef.head(15))\n",
    "\n",
    "    # Visualizaci√≥n\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = feature_coef.head(15)\n",
    "    colors = [\"red\" if x < 0 else \"blue\" for x in top_features[\"coefficient\"]]\n",
    "    sns.barplot(data=top_features, y=\"feature\", x=\"coefficient\", palette=colors)\n",
    "    plt.title(\"Top 15 Coeficientes M√°s Importantes\")\n",
    "    plt.xlabel(\"Coeficiente\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.axvline(x=0, color=\"black\", linestyle=\"-\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    save_current_plot(\"feature_coefficients\", \"../results/figures/modeling\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e7003f",
   "metadata": {},
   "source": [
    "## 10. Resumen Comparativo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ad58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìà RESUMEN COMPARATIVO FINAL\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Crear tabla comparativa final\n",
    "final_comparison = pd.DataFrame(\n",
    "    {\n",
    "        \"Modelo\": list(model_results.keys()) + [f\"{best_model_name} (Optimizado)\"],\n",
    "        \"Validation_F1\": list(comparison_df[\"val_f1\"]) + [tuned_metrics[\"val_f1\"]],\n",
    "        \"Validation_Accuracy\": list(comparison_df[\"val_accuracy\"])\n",
    "        + [tuned_metrics[\"val_accuracy\"]],\n",
    "        \"Validation_AUC\": list(comparison_df[\"val_auc\"]) + [tuned_metrics[\"val_auc\"]],\n",
    "        \"Test_F1\": [None] * len(model_results) + [test_metrics[\"f1\"]],\n",
    "        \"Test_Accuracy\": [None] * len(model_results) + [test_metrics[\"accuracy\"]],\n",
    "        \"Test_AUC\": [None] * len(model_results) + [test_metrics[\"auc\"]],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Comparaci√≥n Final de Modelos:\")\n",
    "print(final_comparison.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c003127",
   "metadata": {},
   "source": [
    "## 11. Guardar Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462b8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüíæ GUARDANDO MODELO FINAL\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Crear directorio si no existe\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "# Guardar modelo optimizado\n",
    "model_path = f'../models/best_model_{best_model_name.lower().replace(\" \", \"_\")}.pkl'\n",
    "joblib.dump(best_model_tuned, model_path)\n",
    "print(f\"‚úÖ Modelo guardado: {model_path}\")\n",
    "\n",
    "# Guardar m√©tricas\n",
    "metrics_path = \"../models/model_metrics.json\"\n",
    "import json\n",
    "\n",
    "all_metrics = {\n",
    "    \"best_model\": best_model_name,\n",
    "    \"best_params\": grid_search.best_params_,\n",
    "    \"base_models_comparison\": model_results,\n",
    "    \"cv_results\": cv_results,\n",
    "    \"final_test_metrics\": test_metrics,\n",
    "}\n",
    "\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    # Convertir numpy types a tipos nativos de Python\n",
    "    def convert_numpy(obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return obj\n",
    "\n",
    "    # Aplicar conversi√≥n recursivamente\n",
    "    def clean_dict(d):\n",
    "        if isinstance(d, dict):\n",
    "            return {k: clean_dict(v) for k, v in d.items()}\n",
    "        elif isinstance(d, list):\n",
    "            return [clean_dict(item) for item in d]\n",
    "        else:\n",
    "            return convert_numpy(d)\n",
    "\n",
    "    clean_metrics = clean_dict(all_metrics)\n",
    "    json.dump(clean_metrics, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ M√©tricas guardadas: {metrics_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f29c13",
   "metadata": {},
   "source": [
    "## 12. Insights y Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9c3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüéØ INSIGHTS Y CONCLUSIONES\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "insights = [\n",
    "    f\"üèÜ Mejor modelo: {best_model_name} con F1={test_metrics['f1']:.4f}\",\n",
    "    f\"üìä Accuracy final en test: {test_metrics['accuracy']:.4f} ({test_metrics['accuracy']*100:.1f}%)\",\n",
    "    f\"üéØ AUC-ROC: {test_metrics['auc']:.4f} (excelente capacidad discriminativa)\",\n",
    "    f\"‚öñÔ∏è Precision: {test_metrics['precision']:.4f}, Recall: {test_metrics['recall']:.4f}\",\n",
    "]\n",
    "\n",
    "performance_analysis = []\n",
    "if test_metrics[\"accuracy\"] > 0.80:\n",
    "    performance_analysis.append(\"‚úÖ Objetivo de >80% accuracy ALCANZADO\")\n",
    "else:\n",
    "    performance_analysis.append(\n",
    "        f\"‚ö†Ô∏è Accuracy {test_metrics['accuracy']*100:.1f}% por debajo del objetivo 80%\"\n",
    "    )\n",
    "\n",
    "if test_metrics[\"auc\"] > 0.85:\n",
    "    performance_analysis.append(\"‚úÖ Excelente capacidad discriminativa (AUC > 0.85)\")\n",
    "elif test_metrics[\"auc\"] > 0.75:\n",
    "    performance_analysis.append(\"‚úÖ Buena capacidad discriminativa (AUC > 0.75)\")\n",
    "\n",
    "print(\"RESULTADOS PRINCIPALES:\")\n",
    "for insight in insights:\n",
    "    print(f\"  {insight}\")\n",
    "\n",
    "print(\"\\nAN√ÅLISIS DE PERFORMANCE:\")\n",
    "for analysis in performance_analysis:\n",
    "    print(f\"  {analysis}\")\n",
    "\n",
    "# An√°lisis de overfitting\n",
    "train_val_diff = tuned_metrics[\"train_accuracy\"] - tuned_metrics[\"val_accuracy\"]\n",
    "if train_val_diff > 0.05:\n",
    "    print(f\"\\n‚ö†Ô∏è POSIBLE OVERFITTING:\")\n",
    "    print(f\"  Diferencia Train-Val: {train_val_diff:.4f}\")\n",
    "    print(f\"  Train Accuracy: {tuned_metrics['train_accuracy']:.4f}\")\n",
    "    print(f\"  Val Accuracy: {tuned_metrics['val_accuracy']:.4f}\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ BUEN BALANCE BIAS-VARIANCE:\")\n",
    "    print(f\"  Diferencia Train-Val: {train_val_diff:.4f} (< 0.05)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778e2901",
   "metadata": {},
   "source": [
    "## 13. Pr√≥ximos Pasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e79fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüöÄ PR√ìXIMOS PASOS\")\n",
    "print(\"=\" * 18)\n",
    "\n",
    "next_steps = [\n",
    "    \"Interpretaci√≥n de Resultados (05_model_evaluation.ipynb)\",\n",
    "    \"- An√°lisis detallado de casos mal clasificados\",\n",
    "    \"- Interpretaci√≥n de feature importance en contexto hist√≥rico\",\n",
    "    \"- Validaci√≥n de insights con conocimiento del dominio\",\n",
    "    \"- An√°lisis de bias en predicciones por subgrupos\",\n",
    "    \"\",\n",
    "    \"Storytelling Final\",\n",
    "    \"- Conexi√≥n de resultados ML con narrativa hist√≥rica\",\n",
    "    \"- Validaci√≥n de hip√≥tesis iniciales\",\n",
    "    \"- Insights para protocolo de emergencias modernas\",\n",
    "    \"- Visualizaciones finales para presentaci√≥n\",\n",
    "    \"\",\n",
    "    \"Documentaci√≥n Completa\",\n",
    "    \"- Actualizar development log con challenges de modelado\",\n",
    "    \"- Completar reporte t√©cnico final\",\n",
    "    \"- Preparar presentaci√≥n ejecutiva\",\n",
    "]\n",
    "\n",
    "for step in next_steps:\n",
    "    if step == \"\":\n",
    "        print()\n",
    "    elif step.startswith(\"-\"):\n",
    "        print(f\"  {step}\")\n",
    "    else:\n",
    "        print(f\"‚Ä¢ {step}\")\n",
    "\n",
    "print(f\"\\n‚úÖ ¬°Modelado completado exitosamente!\")\n",
    "print(\n",
    "    f\"üéØ Modelo final: {best_model_name} con {test_metrics['accuracy']*100:.1f}% accuracy\"\n",
    ")\n",
    "print(f\"üìä Listo para interpretaci√≥n y storytelling final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
