# üî¨ Metodolog√≠a del Proyecto - Titanic Survival Prediction

## üìã Marco Metodol√≥gico

**Proceso Base**: CRISP-DM (Cross-Industry Standard Process for Data Mining)  
**Enfoque**: An√°lisis exploratorio ‚Üí Modelado comparativo ‚Üí Storytelling interpretativo  
**Paradigma**: Supervised Learning - Clasificaci√≥n binaria  

---

## üéØ 1. Business Understanding

### **Definici√≥n del Problema**
- **Tipo**: Clasificaci√≥n binaria (Sobrevivi√≥: S√≠/No)
- **Contexto**: An√°lisis hist√≥rico con implicaciones sociol√≥gicas
- **M√©tricas objetivo**: Accuracy >80%, Interpretabilidad alta
- **Stakeholders**: Acad√©micos, historiadores, estudiantes de ML

### **Success Criteria**
1. **T√©cnico**: Modelo con performance superior a baseline random (50%)
2. **Acad√©mico**: Cumplir 100% requerimientos ML-Practical.pdf
3. **Interpretativo**: Generar insights validables hist√≥ricamente
4. **Educativo**: Demonstrar dominio de algoritmos del curso

---

## üìä 2. Data Understanding

### **Estrategia de An√°lisis Exploratorio**

#### **2.1 An√°lisis Univariado**
```python
# Para cada variable:
# - Distribuci√≥n (histogramas, boxplots)
# - Estad√≠sticas descriptivas (media, mediana, moda)
# - Valores faltantes (cantidad, patr√≥n)
# - Outliers (detecci√≥n visual y estad√≠stica)
```

#### **2.2 An√°lisis Bivariado**
```python
# Variable objetivo vs predictores:
# - Tablas de contingencia (categ√≥ricas)
# - Correlaciones (num√©ricas)
# - Visualizaciones comparativas
# - Tests estad√≠sticos de significancia
```

#### **2.3 An√°lisis Multivariado**
```python
# Interacciones entre variables:
# - Matrices de correlaci√≥n
# - An√°lisis factorial exploratorio
# - Clustering para identificar grupos
# - An√°lisis de correspondencias
```

### **Calidad de Datos - Criterios**

| Dimensi√≥n | Criterio | Acci√≥n |
|-----------|----------|---------|
| **Completitud** | <5% missing ‚Üí OK<br>5-20% ‚Üí Imputar<br>>20% ‚Üí Evaluar eliminaci√≥n | Age: 19.9% ‚Üí Imputar<br>Cabin: 77.1% ‚Üí Eliminar |
| **Consistencia** | Valores en rangos esperados | Age: [0-80] ‚úì<br>Fare: [0-512] ‚úì |
| **Precisi√≥n** | Coherencia con fuentes hist√≥ricas | Validar con Encyclopedia Titanica |
| **Relevancia** | Correlaci√≥n con variable objetivo | Mantener \|corr\| > 0.05 |

---

## üõ†Ô∏è 3. Data Preparation

### **3.1 Estrategia de Limpieza**

#### **Valores Faltantes**
```python
# Age (19.9% missing):
strategies = {
    'simple': df['Age'].fillna(df['Age'].median()),
    'group_median': df.groupby(['Sex', 'Pclass'])['Age'].transform('median'),
    'predictive': RandomForestRegressor(features=['Pclass', 'Sex', 'SibSp', 'Parch', 'Fare'])
}
# Selecci√≥n: Comparar distribuciones resultantes
```

#### **Outliers**
```python
# Criterio: IQR method
def detect_outliers(column):
    Q1 = column.quantile(0.25)
    Q3 = column.quantile(0.75)
    IQR = Q3 - Q1
    return (column < Q1 - 1.5*IQR) | (column > Q3 + 1.5*IQR)

# Acci√≥n: Investigar, no eliminar autom√°ticamente
```

### **3.2 Feature Engineering Strategy**

#### **Variables Derivadas**
```python
features_new = {
    'FamilySize': lambda df: df['SibSp'] + df['Parch'] + 1,
    'IsAlone': lambda df: (df['FamilySize'] == 1).astype(int),
    'Title': lambda df: df['Name'].str.extract('([A-Za-z]+)\.'),
    'AgeGroup': lambda df: pd.cut(df['Age'], bins=[0,12,18,35,60,100], 
                                  labels=['Child','Teen','Adult','Middle','Senior']),
    'FareBin': lambda df: pd.qcut(df['Fare'], q=4, labels=['Low','Medium','High','Premium'])
}
```

#### **Justificaci√≥n Te√≥rica**
- **FamilySize**: Hip√≥tesis de protecci√≥n familiar vs sobrecarga
- **Title**: Indicador de estatus social m√°s granular que Pclass
- **AgeGroup**: Pol√≠tica "ni√±os primero" en grupos etarios
- **FareBin**: Proxy de riqueza independiente de clase

### **3.3 Encoding Strategy**

#### **Variables Categ√≥ricas**
```python
encoding_strategy = {
    'Sex': 'LabelEncoder',  # Binaria: male=0, female=1
    'Embarked': 'OneHotEncoder',  # Nominal: C, Q, S
    'Title': 'TargetEncoder',  # Alta cardinalidad
    'AgeGroup': 'OrdinalEncoder',  # Ordinal natural
    'Pclass': 'keep_numeric'  # Ya ordinal
}
```

### **3.4 Feature Selection**

#### **Criterios de Selecci√≥n**
1. **Correlaci√≥n**: |correlation| > 0.05 con target
2. **Varianza**: Variance threshold > 0.01
3. **Multicolinealidad**: VIF < 5.0
4. **Domain knowledge**: Relevancia hist√≥rica/te√≥rica

#### **M√©todos a Comparar**
```python
selection_methods = [
    'SelectKBest(chi2)',  # Univariado
    'RFE(LogisticRegression)',  # Wrapper
    'SelectFromModel(RandomForest)',  # Embedded
    'manual_domain_knowledge'  # Expert
]
```

---

## ü§ñ 4. Modeling Strategy

### **4.1 Algoritmos Seleccionados**

#### **Justificaci√≥n por Algoritmo**

| Algoritmo | Justificaci√≥n | Fortalezas Esperadas | Debilidades |
|-----------|---------------|---------------------|-------------|
| **Logistic Regression** | Baseline interpretable, asunciones lineales | Coeficientes interpretables, probabilidades calibradas | Asume linealidad |
| **Random Forest** | Maneja interacciones, robusto | Feature importance, maneja outliers | Menos interpretable |
| **SVM** | Boundaries complejas, kernels | Efectivo en alta dimensi√≥n | Hiperpar√°metros sensibles |
| **Naive Bayes** | Baseline probabil√≠stico | R√°pido, maneja missing values | Asume independencia |

### **4.2 Validation Strategy**

#### **Data Splitting**
```python
# Estratificado para mantener proporci√≥n de supervivencia
train_size = 0.70  # 623 samples
val_size = 0.15    # 134 samples  
test_size = 0.15   # 134 samples

# Stratified para balance de clases
stratify_on = ['Survived', 'Sex', 'Pclass']
```

#### **Cross-Validation**
```python
cv_strategy = StratifiedKFold(
    n_splits=5,
    shuffle=True,
    random_state=42
)
# Para model selection y hyperparameter tuning
```

### **4.3 Hyperparameter Optimization**

#### **Grid Search Strategy**
```python
param_grids = {
    'LogisticRegression': {
        'C': [0.01, 0.1, 1, 10, 100],
        'penalty': ['l1', 'l2', 'elasticnet'],
        'solver': ['liblinear', 'saga']
    },
    'RandomForest': {
        'n_estimators': [50, 100, 200],
        'max_depth': [3, 5, 10, None],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4]
    },
    'SVM': {
        'C': [0.1, 1, 10, 100],
        'kernel': ['linear', 'rbf', 'poly'],
        'gamma': ['scale', 'auto', 0.01, 0.1]
    }
}
```

---

## üìè 5. Evaluation Methodology

### **5.1 M√©tricas de Performance**

#### **M√©tricas Primarias**
```python
primary_metrics = {
    'accuracy': 'Proporci√≥n correcta total',
    'f1_score': 'Balance precision-recall',
    'roc_auc': 'Capacidad discriminativa',
    'classification_report': 'Detalle por clase'
}
```

#### **M√©tricas por Contexto**
- **Acad√©mico**: Accuracy (simplicidad interpretativa)
- **M√©dico/Seguridad**: Recall (evitar falsos negativos)
- **Hist√≥rico**: Precision (confianza en predicciones positivas)
- **Cient√≠fico**: AUC-ROC (threshold-independent)

### **5.2 Model Comparison Framework**

#### **Criterios de Comparaci√≥n**
```python
comparison_criteria = {
    'performance': ['accuracy', 'f1', 'auc'],
    'interpretability': ['feature_importance', 'coefficients', 'decision_rules'],
    'robustness': ['cv_std', 'learning_curves', 'validation_curves'],
    'efficiency': ['training_time', 'prediction_time', 'memory_usage'],
    'generalization': ['bias_variance_tradeoff', 'overfitting_indicators']
}
```

### **5.3 Error Analysis**

#### **An√°lisis de Casos Mal Clasificados**
```python
def analyze_errors(y_true, y_pred, X):
    errors = X[y_true != y_pred]
    return {
        'false_positives': analyze_group(errors[y_pred[y_true != y_pred] == 1]),
        'false_negatives': analyze_group(errors[y_pred[y_true != y_pred] == 0]),
        'confusion_patterns': find_common_characteristics(errors)
    }
```

---

## üìä 6. Visualization & Interpretation

### **6.1 Storytelling Framework**

#### **Narrativa Estructurada**
1. **Context Setting**: "Era el 14 de abril de 1912..."
2. **Data Introduction**: "891 historias humanas en n√∫meros..."
3. **Pattern Discovery**: "Los datos revelan que..."
4. **Model Insights**: "Nuestros algoritmos descubrieron..."
5. **Historical Validation**: "Esto confirma que..."
6. **Modern Implications**: "Hoy esto significa..."

### **6.2 Visualization Strategy**

#### **Por Fase del Proyecto**
```python
viz_by_phase = {
    'EDA': ['distributions', 'correlations', 'crosstabs'],
    'Preprocessing': ['before_after_cleaning', 'feature_distributions'],
    'Modeling': ['learning_curves', 'validation_curves'],
    'Evaluation': ['confusion_matrices', 'roc_curves', 'feature_importance'],
    'Interpretation': ['decision_boundaries', 'prediction_examples']
}
```

#### **Principios de Dise√±o**
- **Clarity**: Mensaje claro en 5 segundos
- **Honesty**: No misleading scales/colors
- **Accessibility**: Colorblind-friendly palettes
- **Narrative**: Cada gr√°fico cuenta parte de la historia

---

## üîÑ 7. Iteration & Refinement

### **7.1 Iterative Approach**

#### **Baseline ‚Üí Improvement Cycles**
```
Cycle 1: Simple models, basic features
Cycle 2: Feature engineering, hyperparameter tuning  
Cycle 3: Ensemble methods, advanced techniques
Cycle 4: Error analysis, final refinement
```

### **7.2 Validation Gates**

#### **Go/No-Go Criteria per Phase**
- **EDA**: ‚â•3 significant patterns identified
- **Preprocessing**: Missing values <5%, no data leakage
- **Modeling**: Baseline accuracy >60%
- **Evaluation**: Best model accuracy >75%
- **Interpretation**: ‚â•5 actionable insights generated

---

## üìù 8. Documentation Standards

### **8.1 Code Documentation**
```python
def function_template(param):
    """
    Brief description
    
    Parameters:
    -----------
    param : type
        Description
        
    Returns:
    --------
    type : Description
    
    Example:
    --------
    >>> function_template("example")
    result
    """
    pass
```

### **8.2 Decision Documentation**
- **Rationale**: Por qu√© se tom√≥ cada decisi√≥n t√©cnica
- **Alternatives**: Qu√© otras opciones se consideraron
- **Trade-offs**: Ventajas/desventajas de la elecci√≥n
- **Results**: Impacto medible de la decisi√≥n

---

## ‚úÖ 9. Quality Assurance

### **9.1 Reproducibility Checklist**
- [ ] Random seeds fijos en todo el pipeline
- [ ] Versiones de librer√≠as especificadas
- [ ] Datos originales preservados e inmutables
- [ ] Pipeline documentado paso a paso
- [ ] Resultados validables independientemente

### **9.2 Validation Protocol**
- [ ] Cross-validation en model selection
- [ ] Hold-out test set nunca visto hasta el final
- [ ] M√©tricas reportadas con intervalos de confianza
- [ ] Assumptions de modelos verificadas
- [ ] Resultados consistentes con domain knowledge

---

*Metodolog√≠a aprobada: 26 Mayo 2025*  
*Versi√≥n: 1.0*  
*Pr√≥xima revisi√≥n: Al completar cada fase*