# üìù Development Log - Titanic Survival Prediction

## üìÖ Registro de Desarrollo del Proyecto

**Equipo**: SG1_Team3_ML  
**Integrantes**: Andr√©s L√≥pez, H√©ctor Eguiarte, Yahwthani Morales, Omar Vida√±a  
**Materia**: COM 139 - Simulaci√≥n & Visualizaci√≥n  
**Universidad**: Universidad Panamericana  

---

## üéØ Fase 1: Setup e Inicializaci√≥n del Proyecto

### ‚úÖ **26 Mayo 2025 - Configuraci√≥n Inicial**

**Tareas Completadas:**
- [x] Creaci√≥n de estructura de proyecto profesional
- [x] Configuraci√≥n de entorno virtual y dependencias
- [x] Setup de repositorio Git con .gitignore apropiado
- [x] Documentaci√≥n inicial en README.md

**Decisiones T√©cnicas:**
- **Python 3.9** como versi√≥n base para compatibilidad
- **Conda + pip** para gesti√≥n h√≠brida de dependencias
- **Estructura modular** separando notebooks, src, docs, y scripts
- **Setup.py** para instalaci√≥n como paquete Python

**Herramientas Seleccionadas:**
```yaml
An√°lisis: pandas, numpy, scipy
ML: scikit-learn, xgboost
Visualizaci√≥n: matplotlib, seaborn, plotly
Desarrollo: jupyter, black, flake8
```

**Challenges Identificados:**
- ‚ö†Ô∏è Necesidad de balance entre estructura profesional y simplicidad acad√©mica
- ‚ö†Ô∏è Gesti√≥n de versiones de dependencias para reproducibilidad

---

## üîç Fase 2: An√°lisis Exploratorio de Datos (EDA)

### ‚úÖ **26 Mayo 2025 - EDA Completo**

**Dataset Caracter√≠sticas:**
- **Fuente**: Kaggle Titanic Dataset
- **Dimensiones**: 891 pasajeros √ó 12 caracter√≠sticas
- **Variable objetivo**: Survived (38.4% tasa supervivencia)

**Hallazgos Principales:**

#### üìä **Insights de Supervivencia**
1. **G√©nero es el factor m√°s determinante**:
   - Mujeres: 74.2% supervivencia
   - Hombres: 18.9% supervivencia
   - **Ratio 4:1** a favor de mujeres

2. **Clase social cr√≠tica**:
   - 1¬™ clase: 63.0% supervivencia
   - 2¬™ clase: 47.3% supervivencia  
   - 3¬™ clase: 24.2% supervivencia

3. **Intersecci√≥n g√©nero-clase revel√≥ patr√≥n "Mujeres y ni√±os primero"**:
   - Mujeres 1¬™ clase: **96.8%** supervivencia
   - Hombres 3¬™ clase: **13.5%** supervivencia

#### ‚ùå **Calidad de Datos**
- **Cabin**: 77.1% valores faltantes ‚Üí Candidata a eliminaci√≥n
- **Age**: 19.9% valores faltantes ‚Üí Requiere imputaci√≥n estrat√©gica
- **Embarked**: 0.2% valores faltantes ‚Üí F√°cil de corregir

**Decisiones de Procesamiento:**
- Eliminar variables no predictivas: PassengerId, Name, Ticket
- Estrategia de imputaci√≥n para Age pendiente de definir
- Feature engineering: tama√±o familia, categor√≠as edad, t√≠tulos

**Tools Utilizadas:**
```python
# Visualizaciones efectivas generadas
matplotlib + seaborn  # Gr√°ficos estad√≠sticos
plotly                # Gr√°ficos interactivos
pandas.crosstab()     # An√°lisis categ√≥rico
correlation matrix    # Relaciones num√©ricas
```

**Challenges Encontrados:**

#### üöß **Challenge 1: Visualizaci√≥n Autom√°tica**
**Problema**: Notebooks generan muchos gr√°ficos que se pierden al cerrar  
**Soluci√≥n Implementada**: 
- Funci√≥n `save_plot()` en `src/utils/helpers.py`
- Guarda autom√°ticamente en m√∫ltiples formatos (PNG, SVG)
- Timestamp para versionado

#### üöß **Challenge 2: Balance Complejidad vs Insights**
**Problema**: Tentaci√≥n de sobre-analizar vs necesidad de insights claros  
**Soluci√≥n**: 
- Enfoque en top 3 factores predictivos: G√©nero, Clase, Age
- Visualizaciones que cuentan historia clara
- M√©tricas simples pero efectivas

#### üöß **Challenge 3: Interpretaci√≥n de Correlaciones**
**Problema**: Correlaciones bajas en variables num√©ricas (-0.338 max)  
**Aprendizaje**: 
- Variables categ√≥ricas m√°s importantes que num√©ricas
- Necesidad de feature engineering
- Interacciones entre variables cr√≠ticas

**Referencias Consultadas:**
- [Kaggle Titanic Tutorials](https://www.kaggle.com/learn/intro-to-machine-learning)
- [Seaborn Documentation](https://seaborn.pydata.org/)
- Documentaci√≥n scikit-learn para preprocessing

---

## üîÑ Fase 3: Data Cleaning & Preprocessing (En Progreso)

### üöß **Pr√≥ximos Challenges Identificados:**

#### **Challenge Anticipado 1: Imputaci√≥n de Age**
**Opciones consideradas**:
1. Media/Mediana simple
2. Imputaci√≥n por clase y g√©nero
3. Modelo predictivo (KNN, Random Forest)
4. M√∫ltiple imputation

**Criterio de decisi√≥n**: Balance entre precisi√≥n y simplicidad

#### **Challenge Anticipado 2: Feature Engineering**
**Variables a crear**:
- `FamilySize` = SibSp + Parch + 1
- `IsAlone` = FamilySize == 1
- `Title` extra√≠do de Name (Mr, Mrs, Miss, Master, etc.)
- `AgeGroup` = categor√≠as de edad
- `FareBin` = categor√≠as de tarifa

#### **Challenge Anticipado 3: Encoding Categ√≥rico**
**Decisiones pendientes**:
- One-hot encoding vs Label encoding
- Manejo de variables ordinales (Pclass)
- Estrategia para variables de alta cardinalidad

---

## üìä M√©tricas de Progreso

| Fase | Completado | Tiempo Estimado | Tiempo Real | Estado |
|------|------------|-----------------|-------------|---------|
| Setup | 100% | 2h | 1.5h | ‚úÖ |
| EDA | 100% | 6h | 4h | ‚úÖ |
| Cleaning | 0% | 4h | - | üöß |
| Feature Eng. | 0% | 3h | - | ‚è≥ |
| Modeling | 0% | 6h | - | ‚è≥ |
| Evaluation | 0% | 3h | - | ‚è≥ |

**Total Progreso**: 35% completado

---

## üéì Lecciones Aprendidas

### **T√©cnicas:**
1. **EDA estructurado es fundamental** - Insights claros antes de modelado
2. **Visualizaci√≥n cuenta historia** - Gr√°ficos comunican mejor que n√∫meros
3. **Variables categ√≥ricas dominan** - En este dataset, g√©nero/clase > edad/tarifa

### **Metodol√≥gicas:**
1. **Documentaci√≥n paralela** - Escribir insights mientras se descubren
2. **C√≥digo modular desde inicio** - Funciones helper ahorran tiempo
3. **Versioning visual** - Guardar gr√°ficos importantes autom√°ticamente

### **De Dominio:**
1. **"Mujeres y ni√±os primero"** se refleja claramente en datos
2. **Clase social** = acceso a botes salvavidas
3. **Familia** puede ser ventaja o desventaja seg√∫n tama√±o

---

## üîÆ Pr√≥ximos Pasos

### **Inmediatos (Esta Semana):**
- [ ] Implementar estrategia de imputaci√≥n para Age
- [ ] Feature engineering b√°sico
- [ ] Data cleaning pipeline completo
- [ ] Notebook 02_data_cleaning.ipynb

### **Siguientes (Pr√≥xima Semana):**
- [ ] Selecci√≥n de algoritmos ML
- [ ] Implementaci√≥n de modelos base
- [ ] Cross-validation strategy
- [ ] M√©tricas de evaluaci√≥n

### **Finales:**
- [ ] Model comparison y tunning
- [ ] Interpretaci√≥n de resultados
- [ ] Storytelling final
- [ ] Documentaci√≥n completa

---

## üìö Referencias y Recursos

**Documentaci√≥n T√©cnica:**
- [Pandas User Guide](https://pandas.pydata.org/docs/user_guide/)
- [Scikit-learn Preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html)
- [Matplotlib Tutorials](https://matplotlib.org/stable/tutorials/index.html)

**Inspiraci√≥n de An√°lisis:**
- Kaggle Titanic Kernels (Top notebooks)
- [Towards Data Science - Titanic](https://towardsdatascience.com/tagged/titanic)

**Metodolog√≠a:**
- CRISP-DM Process
- ML-Practical.pdf (Documento del curso)

---

*Log actualizado: 26 Mayo 2025, 18:30*  
*Pr√≥xima actualizaci√≥n: 28 Mayo 2025*