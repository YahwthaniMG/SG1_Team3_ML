# üìù Development Log - Titanic Survival Prediction

## üìÖ Registro de Desarrollo del Proyecto

**Equipo**: SG1_Team3_ML  
**Integrantes**: Andr√©s L√≥pez, H√©ctor Eguiarte, Yahwthani Morales, Omar Vida√±a  
**Materia**: COM 139 - Simulaci√≥n & Visualizaci√≥n  
**Universidad**: Universidad Panamericana  

---

## üéØ Fase 1: Setup e Inicializaci√≥n del Proyecto

### ‚úÖ **28 Mayo 2025 - Configuraci√≥n Inicial**

**Tareas Completadas:**
- [x] Creaci√≥n de estructura de proyecto profesional
- [x] Configuraci√≥n de entorno virtual y dependencias
- [x] Setup de repositorio Git con .gitignore apropiado
- [x] Documentaci√≥n inicial en README.md

**Decisiones T√©cnicas:**
- **Python 3.9** como versi√≥n base para compatibilidad
- **Conda + pip** para gesti√≥n h√≠brida de dependencias
- **Estructura modular** separando notebooks, src, docs, y scripts
- **Setup.py** para instalaci√≥n como paquete Python

**Herramientas Seleccionadas:**
```yaml
An√°lisis: pandas, numpy, scipy
ML: scikit-learn, xgboost
Visualizaci√≥n: matplotlib, seaborn, plotly
Desarrollo: jupyter, black, flake8
```

**Challenges Identificados:**
- ‚ö†Ô∏è Necesidad de balance entre estructura profesional y simplicidad acad√©mica
- ‚ö†Ô∏è Gesti√≥n de versiones de dependencias para reproducibilidad

---

## üîç Fase 2: An√°lisis Exploratorio de Datos (EDA)

### ‚úÖ **28 Mayo 2025 - EDA Completo**

**Dataset Caracter√≠sticas:**
- **Fuente**: Kaggle Titanic Dataset
- **Dimensiones**: 891 pasajeros √ó 12 caracter√≠sticas
- **Variable objetivo**: Survived (38.4% tasa supervivencia)

**Hallazgos Principales:**

#### üìä **Insights de Supervivencia**
1. **G√©nero es el factor m√°s determinante**:
   - Mujeres: 74.2% supervivencia
   - Hombres: 18.9% supervivencia
   - **Ratio 4:1** a favor de mujeres

2. **Clase social cr√≠tica**:
   - 1¬™ clase: 63.0% supervivencia
   - 2¬™ clase: 47.3% supervivencia  
   - 3¬™ clase: 24.2% supervivencia

3. **Intersecci√≥n g√©nero-clase revel√≥ patr√≥n "Mujeres y ni√±os primero"**:
   - Mujeres 1¬™ clase: **96.8%** supervivencia
   - Hombres 3¬™ clase: **13.5%** supervivencia

#### ‚ùå **Calidad de Datos**
- **Cabin**: 77.1% valores faltantes ‚Üí Candidata a eliminaci√≥n
- **Age**: 19.9% valores faltantes ‚Üí Requiere imputaci√≥n estrat√©gica
- **Embarked**: 0.2% valores faltantes ‚Üí F√°cil de corregir

**Decisiones de Procesamiento:**
- Eliminar variables no predictivas: PassengerId, Name, Ticket
- Estrategia de imputaci√≥n para Age pendiente de definir
- Feature engineering: tama√±o familia, categor√≠as edad, t√≠tulos

**Tools Utilizadas:**
```python
# Visualizaciones efectivas generadas
matplotlib + seaborn  # Gr√°ficos estad√≠sticos
plotly                # Gr√°ficos interactivos
pandas.crosstab()     # An√°lisis categ√≥rico
correlation matrix    # Relaciones num√©ricas
```

**Challenges Encontrados:**

#### üöß **Challenge 1: Visualizaci√≥n Autom√°tica**
**Problema**: Notebooks generan muchos gr√°ficos que se pierden al cerrar  
**Soluci√≥n Implementada**: 
- Funci√≥n `save_plot()` en `src/utils/helpers.py`
- Guarda autom√°ticamente en m√∫ltiples formatos (PNG, SVG)
- Timestamp para versionado

#### üöß **Challenge 2: Balance Complejidad vs Insights**
**Problema**: Tentaci√≥n de sobre-analizar vs necesidad de insights claros  
**Soluci√≥n**: 
- Enfoque en top 3 factores predictivos: G√©nero, Clase, Age
- Visualizaciones que cuentan historia clara
- M√©tricas simples pero efectivas

#### üöß **Challenge 3: Interpretaci√≥n de Correlaciones**
**Problema**: Correlaciones bajas en variables num√©ricas (-0.338 max)  
**Aprendizaje**: 
- Variables categ√≥ricas m√°s importantes que num√©ricas
- Necesidad de feature engineering
- Interacciones entre variables cr√≠ticas

**Referencias Consultadas:**
- [Kaggle Titanic Tutorials](https://www.kaggle.com/learn/intro-to-machine-learning)
- [Seaborn Documentation](https://seaborn.pydata.org/)
- Documentaci√≥n scikit-learn para preprocessing

---

## üîÑ Fase 3: Data Cleaning & Preprocessing (Completado)

### ‚úÖ **29 Mayo 2025 - Data Cleaning Exitoso**

**Estrategias Implementadas:**
- **Age (19.9% faltantes)**: Imputaci√≥n por mediana agrupada (Sex + Pclass)
- **Cabin (77.1% faltantes)**: Convertida a variable binaria `Cabin_Known`
- **Embarked (0.2% faltantes)**: Imputaci√≥n con moda (Southampton)
- **Outliers**: Analizados y mantenidos (hist√≥ricamente v√°lidos)

**Decisiones Tomadas:**
- Eliminaci√≥n de PassengerId, Name, Ticket (no predictivos)
- Mantener outliers de Fare (suites de lujo leg√≠timas)
- Mantener outliers de Age (beb√©s/ancianos realistas en 1912)

---

## üîß Fase 4: Feature Engineering (Completado)

### ‚úÖ **29 Mayo 2025 - Feature Engineering Exitoso**

**Nuevas Variables Creadas:**

#### üìä **Variables Derivadas Exitosas:**
1. **FamilySize**: Familias 2-4 personas ‚Üí 55-72% supervivencia
2. **IsAlone**: Acompa√±ados (50.6%) vs Solos (30.4%) supervivencia
3. **AgeGroup**: Ni√±os (57.4%) > Adultos j√≥venes (33.7%) > Seniors (26.9%)
4. **FareBin**: Premium (58.1%) > High (45.5%) > Medium (30.4%) > Low (19.7%)
5. **Title**: Mrs (79.4%) > Miss (70.1%) > Master (57.5%) > Mr (15.7%)

#### üîó **Variables de Interacci√≥n Poderosas:**
- **Sex_Pclass**: female_Class1 (96.8%) vs male_Class3 (13.5%)
- **Age_Sex**: Adult_Female (75.3%) > Young (54.0%) > Adult_Male (16.6%)

**Encoding Estrat√©gico:**
- **Label**: Variables binarias (Sex, Embarked)
- **Ordinal**: Variables ordenadas (AgeGroup, FareBin)  
- **One-Hot**: Variables nominales (Title, interacciones)

**Resultado Final:**
- De 9 variables originales ‚Üí **29 features**
- **Top 3 predictores**: AgeSex_Adult_Female (0.486), SexPclass_female_Class1 (0.413), Title_Mrs (0.342)

#### üöß **Challenges Encontrados:**

#### **Challenge 4: Balance de Features**
**Problema**: Riesgo de overfitting con 29 features en dataset de 891 registros  
**Soluci√≥n Implementada**: 
- Correlaci√≥n analysis para identificar features m√°s importantes
- Encoding estrat√©gico (no dummy trap)
- Preparaci√≥n para feature selection en modelado

#### **Challenge 5: Interpretabilidad vs Performance**
**Problema**: Variables de interacci√≥n mejoran predicci√≥n pero complican interpretaci√≥n  
**Aprendizaje**: 
- Mantener variables originales para interpretaci√≥n
- Variables de interacci√≥n para performance
- Documentar claramente cada feature

#### **Challenge 6: Scaling de Variables Mixtas**
**Problema**: Mezcla de variables continuas, ordinales y dummies  
**Soluci√≥n**: 
- StandardScaler solo en variables num√©ricas
- Mantener dummies en escala 0-1 original
- Verificaci√≥n estad√≠stica del scaling

---

## üìä M√©tricas de Progreso

| Fase | Completado | Tiempo Estimado | Tiempo Real | Estado |
|------|------------|-----------------|-------------|---------|
| Setup | 100% | 2h | 1.5h | ‚úÖ |
| EDA | 100% | 6h | 4h | ‚úÖ |
| Cleaning | 100% | 4h | 3h | ‚úÖ |
| Feature Eng. | 100% | 3h | 2.5h | ‚úÖ |
| Modeling | 0% | 6h | - | üöß |
| Evaluation | 0% | 3h | - | ‚è≥ |

**Total Progreso**: 70% completado

---

## üéì Lecciones Aprendidas

### **T√©cnicas:**
1. **EDA estructurado es fundamental** - Insights claros antes de modelado
2. **Visualizaci√≥n cuenta historia** - Gr√°ficos comunican mejor que n√∫meros
3. **Variables categ√≥ricas dominan** - En este dataset, g√©nero/clase > edad/tarifa

### **Metodol√≥gicas:**
1. **Documentaci√≥n paralela** - Escribir insights mientras se descubren
2. **C√≥digo modular desde inicio** - Funciones helper ahorran tiempo
3. **Versioning visual** - Guardar gr√°ficos importantes autom√°ticamente

### **De Dominio:**
1. **"Mujeres y ni√±os primero"** se refleja claramente en datos
2. **Clase social** = acceso a botes salvavidas
3. **Familia** puede ser ventaja o desventaja seg√∫n tama√±o

---

## üîÆ Pr√≥ximos Pasos

### **Inmediatos (Esta Semana):**
- [x] Implementar estrategia de imputaci√≥n para Age
- [x] Feature engineering b√°sico
- [x] Data cleaning pipeline completo
- [x] Notebook 02_data_cleaning.ipynb
- [x] Notebook 03_feature_engineering.ipynb
- [ ] Implementar algoritmos de Machine Learning
- [ ] Notebook 04_modeling.ipynb

### **Siguientes (Pr√≥xima Semana):**
- [ ] Comparaci√≥n de modelos y tunning
- [ ] Cross-validation strategy
- [ ] M√©tricas de evaluaci√≥n
- [ ] Interpretaci√≥n de feature importance

### **Finales:**
- [ ] Error analysis y model improvement
- [ ] Storytelling final
- [ ] Documentaci√≥n completa
- [ ] Reporte t√©cnico final

---

## üìö Referencias y Recursos

**Documentaci√≥n T√©cnica:**
- [Pandas User Guide](https://pandas.pydata.org/docs/user_guide/)
- [Scikit-learn Preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html)
- [Matplotlib Tutorials](https://matplotlib.org/stable/tutorials/index.html)

**Inspiraci√≥n de An√°lisis:**
- Kaggle Titanic Kernels (Top notebooks)
- [Towards Data Science - Titanic](https://towardsdatascience.com/tagged/titanic)

**Metodolog√≠a:**
- CRISP-DM Process
- ML-Practical.pdf (Documento del curso)

---

*Log actualizado: 28 Mayo 2025, 18:30*  
*Pr√≥xima actualizaci√≥n: 29 Mayo 2025*