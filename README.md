# üö¢ Titanic Survival Prediction

## üìñ Project Description

This project uses Machine Learning techniques to predict RMS Titanic passenger survival based on demographic and socioeconomic characteristics. Developed as an academic project for the course COM 139 - Simulation & Visualization at Universidad Panamericana.

### üéØ Objectives
- Analyze factors influencing Titanic survival
- Implement and compare different classification algorithms
- Create visualizations that tell the data story
- Discover hidden patterns in historical data
- Quantitatively validate the "women and children first" protocol

## üèÜ Key Results

- **üéØ Academic Goal**: ‚úÖ **ACHIEVED** - Accuracy exceeding the required 80%
- **ü§ñ Best Model**: Support Vector Machine (SVM) with RBF kernel
- **üìä Final Performance**: **84.4% accuracy** on test set
- **üîç Balanced Metrics**: F1-Score: 0.78, Precision: 0.85, Recall: 0.72, AUC-ROC: 0.86
- **üß™ Demonstrated Validation**: 87.0% accuracy on final validation data

### üìà Algorithm Comparison

| Model | Accuracy | F1-Score | AUC-ROC | Interpretability |
|--------|----------|----------|---------|-------------------|
| **SVM (Winner)** | **84.4%** | **0.781** | **0.859** | Medium |
| Logistic Regression | 84.3% | 0.781 | **0.910** | **High** |
| Random Forest | 83.2% | 0.783 | 0.879 | Medium |
| Naive Bayes | 82.0% | 0.750 | 0.876 | Medium |

## üìä Dataset and Features

- **Source**: [Kaggle - Titanic Dataset](https://www.kaggle.com/datasets/yasserh/titanic-dataset)
- **Dimensions**: 891 passengers √ó 12 original features ‚Üí **29 engineered features**
- **Target variable**: Survived (38.4% historical survival rate)
- **Quality**: Complete missing value processing and advanced feature engineering

### üîç Top Most Predictive Features
1. **AgeSex_Adult_Female** (r=0.486): Adult women
2. **SexPclass_female_Class1** (r=0.413): First-class women  
3. **Title_Mrs** (r=0.342): Female social status

## üèõÔ∏è Validated Historical Insights

- **‚úÖ "Women and Children First" Protocol**: Women 74.2% vs Men 18.9% survival (4:1 ratio)
- **‚úÖ Social Class Determinant**: 1st class (63%) > 2nd class (47%) > 3rd class (24%)
- **‚úÖ Critical Intersection**: 1st class women 96.8% vs 3rd class men 13.5%
- **‚úÖ Quantitative Validation**: Data confirms historical disaster narratives

## üìÅ Project Structure

```
SG1_Team3_ML/
‚îú‚îÄ‚îÄ üìã DOCUMENTATION
‚îÇ   ‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ project_proposal.md          # Initial project proposal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ methodology.md               # Detailed CRISP-DM methodology
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_dictionary.md           # Complete data dictionary
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ development_log.md           # ‚≠ê Detailed development log
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ final_technical_report.md    # ‚≠ê Complete technical report
‚îÇ
‚îú‚îÄ‚îÄ üìì NOTEBOOKS (Complete ML Pipeline)
‚îÇ   ‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01_exploratory_data_analysis.ipynb    # Complete EDA
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_data_cleaning.ipynb               # Data cleaning
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 03_feature_engineering.ipynb        # Feature engineering
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 04_modeling.ipynb                   # ‚≠ê Model training
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 05_model_evaluation.ipynb           # Evaluation and analysis
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 06_final_predictions.ipynb          # ‚≠ê Final predictions
‚îÇ
‚îú‚îÄ‚îÄ üìä DATA
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ raw/titanic.csv              # Original Kaggle dataset
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ processed/                   # Processed data and features
‚îÇ
‚îú‚îÄ‚îÄ ü§ñ MODELS
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ best_model_svm.pkl          # ‚≠ê Final trained SVM model
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_metrics.json          # Model metrics and parameters
‚îÇ
‚îú‚îÄ‚îÄ üìà RESULTS
‚îÇ   ‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ figures/                    # All generated visualizations
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ reports/                    # Automatic HTML reports
‚îÇ
‚îú‚îÄ‚îÄ üîß SOURCE CODE
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/helpers.py            # Utility functions
‚îÇ
‚îî‚îÄ‚îÄ üìã CONFIGURATION
    ‚îú‚îÄ‚îÄ requirements.txt                 # Python dependencies
    ‚îú‚îÄ‚îÄ environment.yml                  # Conda environment
    ‚îî‚îÄ‚îÄ setup.py                        # Package configuration
```

## üîë Key Files to Review

### üìã **Main Documentation**
- **`docs/final_technical_report.md`** - Complete technical report with all results
- **`docs/development_log.md`** - Detailed development process log
- **`docs/methodology.md`** - Implemented CRISP-DM methodology

### üß™ **Executable Notebooks**
- **`notebooks/04_modeling.ipynb`** - Model training and comparison
- **`notebooks/06_final_predictions.ipynb`** - Final predictions demonstration
- **`notebooks/01_exploratory_data_analysis.ipynb`** - Complete exploratory analysis

### ü§ñ **Production Model**
- **`models/best_model_svm.pkl`** - Trained SVM model ready for use
- **`models/model_metrics.json`** - Complete performance metrics

## üõ†Ô∏è Installation and Execution

### Option 1: Conda (Recommended)
```bash
# Clone repository
git clone https://github.com/YahwthaniMG/SG1_Team3_ML.git
cd SG1_Team3_ML

# Create environment
conda env create -f environment.yml
conda activate SG1_Team3_ML

# Run notebooks
jupyter notebook notebooks/
```

### Option 2: pip + venv
```bash
# Clone repository
git clone https://github.com/YahwthaniMG/SG1_Team3_ML.git
cd SG1_Team3_ML

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run notebooks
jupyter notebook notebooks/
```

### üöÄ Quick Start

To see results immediately:

1. **View Results**: Open `docs/final_technical_report.md`
2. **Run Predictions**: Notebook `06_final_predictions.ipynb`
3. **Complete Pipeline**: Run notebooks 01-06 in order

## üìä Prediction Demonstration

The final model can predict survival on new data:

```python
# Example usage of trained model
import joblib
model = joblib.load('models/best_model_svm.pkl')

# Model achieved in demonstration:
# - 87.0% accuracy on 100 test passengers
# - 35% predicted as survivors (vs 38.4% historical)
# - 78% high-confidence predictions
```

## üéì Demonstrated Academic Value

### ‚úÖ **Achieved Technical Objectives**
- **Complete ML Pipeline**: CRISP-DM implemented end-to-end
- **Algorithm Comparison**: 4 algorithms systematically evaluated
- **Superior Performance**: 84.4% accuracy (target >80% ‚úÖ)
- **Rigorous Validation**: Cross-validation, test set holdout, balanced metrics

### üèõÔ∏è **Historical Contribution**
- **Quantitative Validation**: "Women and children first" protocol statistically confirmed
- **Intersectionality**: Gender + Social class as critical determining factor  
- **Exceptional Cases**: Error analysis reveals extraordinary human stories
- **Modern Lessons**: Insights applicable to current emergency protocols

### üî¨ **Methodological Rigor**
- **Reproducibility**: All code and pipeline documented
- **Transparency**: Development log with all challenges and decisions
- **Validation**: Consistent and statistically significant results

## üë®‚Äçüéì Development Team

**SG1_Team3_ML** - Universidad Panamericana, Spring 2025

- **Andr√©s L√≥pez √Ålvarez** - Feature Engineering & Modeling
- **H√©ctor Manuel Eguiarte Carlos** - Visualization & Storytelling  
- **Yahwthani Morales G√≥mez** - Project Lead & Data Pipeline
- **Omar Vida√±a Rodr√≠guez** - Model Evaluation & Performance Analysis

**Instructor**: Gabriel Castillo Cort√©s  
**Course**: COM 139 - Simulation & Visualization

## üìö References and Sources

### **Historical Data**
- [Kaggle Titanic Dataset](https://www.kaggle.com/datasets/yasserh/titanic-dataset)
- Encyclopedia Titanica (historical validation)
- British Board of Trade Report (1912)

### **Technical Methodology**
- James, G. et al. "An Introduction to Statistical Learning"
- Castillo, G. "ML-Practical.pdf" (course base document)
- Scikit-learn documentation

### **Historical Context**
- Lord, Walter. "A Night to Remember" (1955)
- Official British disaster investigation (1912)

---

## üéØ Conclusion

This project successfully demonstrates the application of Machine Learning to validate historical narratives, achieving not only academic technical objectives but also generating valuable insights about one of the most studied events in maritime history.

**The final SVM model not only predicts survival with 84.4% accuracy but also quantitatively reveals how 1912 social structure literally determined life and death on the Titanic.**

---

*Want to explore more? Start with `docs/final_technical_report.md` for the complete analysis or run `notebooks/06_final_predictions.ipynb` to see the model in action.*